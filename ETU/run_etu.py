#!/usr/bin/env python3
"""
ETU ê¸°ë³¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (H200 GPU ìµœì í™”)
"""

import os
import sys
import torch

# H200 GPU í™˜ê²½ ìµœì í™”
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # ë‹¨ì¼ GPU ì‚¬ìš© (ì•ˆì „)
os.environ["TOKENIZERS_PARALLELISM"] = "false"  # í† í¬ë‚˜ì´ì € ë³‘ë ¬í™” ë¹„í™œì„±í™”

def main():
    print("=== ETU H200 GPU ìµœì í™” ì‹¤í–‰ ===")
    
    # GPU í™˜ê²½ í™•ì¸
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        memory_gb = torch.cuda.get_device_properties(current_device).total_memory / 1024**3
        
        print(f"âœ… GPU í™˜ê²½ ê°ì§€: {device_name}")
        print(f"   GPU ê°œìˆ˜: {gpu_count}")
        print(f"   í˜„ì¬ GPU: {current_device}")
        print(f"   ë©”ëª¨ë¦¬: {memory_gb:.1f} GB")
        
        # H200 í™˜ê²½ ìµœì í™” ê¶Œì¥ì‚¬í•­
        if "H200" in device_name:
            print("ğŸš€ H200 GPU ê°ì§€! ìµœì í™”ëœ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            print("   - batch_size: 8 (ê¶Œì¥)")
            print("   - frozen_on_cpu: false (GPU ë©”ëª¨ë¦¬ ì—¬ìœ )")
            print("   - lora_r: 512 (ë†’ì€ ì„±ëŠ¥)")
        else:
            print("âš ï¸  H200ì´ ì•„ë‹Œ GPUì…ë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print("âŒ CUDA GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        from etu.unlearn import run_etu, get_args
        
        # H200 ìµœì í™”ëœ ê¸°ë³¸ ì¸ì
        args = get_args()
        
        # H200 í™˜ê²½ì— ë§ëŠ” ê¸°ë³¸ê°’ ì˜¤ë²„ë¼ì´ë“œ
        if "H200" in device_name:
            args.batch_size = 8
            args.frozen_on_cpu = False
            args.lora_r = 512
            args.lora_alpha = 1024
            args.max_num_batches = 100
            print("ğŸ”§ H200 ìµœì í™” ì„¤ì • ì ìš©ë¨")
        
        print(f"ğŸ“Š ì‹¤í–‰ ì„¤ì •:")
        print(f"   - batch_size: {args.batch_size}")
        print(f"   - frozen_on_cpu: {args.frozen_on_cpu}")
        print(f"   - lora_r: {args.lora_r}")
        print(f"   - max_num_batches: {args.max_num_batches}")
        
        # ETU ì‹¤í–‰
        run_etu(args)
        
    except ImportError as e:
        print(f"âŒ ETU ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
        print("   pip install -r requirements.txt ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 