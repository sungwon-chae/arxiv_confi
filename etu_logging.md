#!/bin/bash
# 8ëŒ€ H200 GPU ëŒ€ìš©ëŸ‰ ëª¨ë¸ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (2025-09, Scout í¬í•¨, Zephyr ë©€í‹°ë„ë©”ì¸)
set -euo pipefail

echo "=== ETU 8x H200 Large-model Experiments (2025-09) ==="
echo "Starting at: $(date)"

# 8ëŒ€ H200 GPU í™˜ê²½ í™•ì¸
GPU_COUNT=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | wc -l)
H200_COUNT=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | grep -c "H200")

echo "ğŸ” GPU í™˜ê²½ ë¶„ì„:"
echo "   - ì´ GPU ê°œìˆ˜: $GPU_COUNT"
echo "   - H200 GPU ê°œìˆ˜: $H200_COUNT"

if [ "$H200_COUNT" -lt 8 ]; then
  echo "âš ï¸  H200 GPUê°€ 8ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ì¼ë¶€ ì‹¤í—˜ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤."
  MAX_GPU=$H200_COUNT
else
  echo "âœ… 8ëŒ€ H200 GPU ëª¨ë‘ ê°ì§€ë¨! ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰ ê°€ëŠ¥"
  MAX_GPU=8
fi
echo ""

###############################################################################
# 1) OpenAI GPT-OSS-20B (ê²½ëŸ‰ MoE) â€” DDP
echo "=== gpt-oss-20b ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy ddp \
  --model_name_or_path "openai/gpt-oss-20b" \
  --batch_size 128 \
  --max_num_batches 500 \
  --lora_r 512 \
  --lora_alpha 1024 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 2) OpenAI GPT-OSS-120B (ëŒ€í˜• MoE) â€” FSDP
echo "=== gpt-oss-120b ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy fsdp \
  --model_name_or_path "openai/gpt-oss-120b" \
  --batch_size 24 \
  --max_num_batches 500 \
  --lora_r 1024 \
  --lora_alpha 2048 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 3) Qwen3-32B (dense) â€” DDP
echo "=== Qwen3-32B ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy ddp \
  --model_name_or_path "Qwen/Qwen3-32B" \
  --batch_size 64 \
  --max_num_batches 500 \
  --lora_r 768 \
  --lora_alpha 1536 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 4) DeepSeek-R1-Distill-Qwen-32B â€” FSDP
echo "=== DeepSeek-R1-Distill-Qwen-32B ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy fsdp \
  --model_name_or_path "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B" \
  --batch_size 48 \
  --max_num_batches 500 \
  --lora_r 768 \
  --lora_alpha 1536 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 5) DeepSeek-R1-Distill-Qwen-14B â€” DDP
echo "=== DeepSeek-R1-Distill-Qwen-14B ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy ddp \
  --model_name_or_path "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B" \
  --batch_size 160 \
  --max_num_batches 500 \
  --lora_r 512 \
  --lora_alpha 1024 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 6) Meta Llama 4 Scout (109B) â€” FSDP
echo "=== Llama-4-Scout-109B ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy fsdp \
  --model_name_or_path "meta-llama/Llama-4-Scout-109B" \
  --batch_size 16 \
  --max_num_batches 500 \
  --lora_r 1024 \
  --lora_alpha 2048 \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

# 7) ë©€í‹° ë„ë©”ì¸ ëŒ€ìš©ëŸ‰ ì‹¤í—˜ â€” Zephyr-7B # batch size 512ë¡œ í–¥ìƒ (ë¦¬ì†ŒìŠ¤ ë„‰ë„‰í•¨)
echo "=== ë©€í‹° ë„ë©”ì¸ (Zephyr-7B) ì‹¤í—˜ ì‹œì‘ ==="
python run_etu_multi_h200.py \
  --strategy ddp \
  --model_name_or_path "HuggingFaceH4/zephyr-7b-beta" \
  --batch_size 512 \
  --max_num_batches 500 \
  --lora_r 512 \
  --lora_alpha 1024 \
  --forget_corpora "cais/wmdp-corpora:cyber-forget-corpus" \
  --retain_corpora "cais/wmdp-corpora:bio-retain-corpus" \
  --epsilon 0.05 \
  --lambda_max 30 \
  --trust_remote_code \
  --verbose

echo "=== ëª¨ë“  ëŒ€ìš©ëŸ‰ ëª¨ë¸ ì‹¤í—˜ ì™„ë£Œ ==="
echo "Completed at: $(date)"
echo "Results saved in models/ directory"
