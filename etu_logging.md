#!/usr/bin/env python3
"""
HuggingFace ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
"""

import os
from datasets import load_dataset
from huggingface_hub import HfApi

def download_dataset(dataset_name, config=None, split="train", local_dir="./datasets"):
    """ë°ì´í„°ì…‹ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ"""
    try:
        print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {dataset_name}")
        
        if config:
            # configê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: cais/wmdp-corpora:cyber-forget-corpus)
            dataset = load_dataset(dataset_name, config, split=split, cache_dir=local_dir)
            print(f"âœ… {dataset_name}:{config} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ - {len(dataset)}ê°œ í•­ëª©")
        else:
            # configê°€ ì—†ëŠ” ê²½ìš° (ì˜ˆ: wikitext, bio-forget-corpus)
            dataset = load_dataset(dataset_name, split=split, cache_dir=local_dir)
            print(f"âœ… {dataset_name} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ - {len(dataset)}ê°œ í•­ëª©")
            
        return True
        
    except Exception as e:
        print(f"âŒ {dataset_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def test_token():
    """í† í° ìœ íš¨ì„± í…ŒìŠ¤íŠ¸"""
    try:
        token = os.getenv("HUGGING_FACE_HUB_TOKEN", "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")
        api = HfApi(token=token)
        
        # ì‚¬ìš©ì ì •ë³´ í™•ì¸
        user = api.whoami()
        print(f"âœ… ë¡œê·¸ì¸ ì„±ê³µ: {user['name']}")
        
        # ë°ì´í„°ì…‹ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ (generatorë¥¼ listë¡œ ë³€í™˜)
        datasets = list(api.list_datasets(author='cais'))
        print(f"âœ… cais ë°ì´í„°ì…‹ ì ‘ê·¼ ê°€ëŠ¥: {len(datasets)}ê°œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ í† í° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜"""
    # í† í° ì„¤ì • (ì§ì ‘ í¬í•¨)
    token = "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"
    os.environ["HUGGING_FACE_HUB_TOKEN"] = token
    
    print("ğŸ”‘ HuggingFace í† í° ì„¤ì • ì™„ë£Œ")
    print(f"ğŸ”‘ ì‚¬ìš© í† í°: {token[:10]}...{token[-10:]}")
    
    # í† í° í…ŒìŠ¤íŠ¸
    if not test_token():
        print("âŒ í† í°ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í† í°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print("ğŸ’¡ í† í°ì´ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ê¶Œí•œì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    
    # ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì…‹ ëª©ë¡ (ìˆ˜ì •ëœ ë²„ì „)
    datasets = [
        ("cais/wmdp-corpora", "cyber-forget-corpus"),
        ("cais/wmdp-corpora", "cyber-retain-corpus"), 
        ("cais/wmdp-bio-forget-corpus", None),  # ë³„ë„ ë°ì´í„°ì…‹
        ("cais/wmdp-corpora", "bio-retain-corpus"),
        ("wikitext", "wikitext-2-raw-v1"),  # config ëª…ì‹œ
    ]
    
    print("\nğŸš€ HuggingFace ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    success_count = 0
    for dataset_name, config in datasets:
        if download_dataset(dataset_name, config):
            success_count += 1
    
    print(f"\nğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(datasets)}")
    print("ğŸ’¾ ë°ì´í„°ëŠ” ./datasets/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 
