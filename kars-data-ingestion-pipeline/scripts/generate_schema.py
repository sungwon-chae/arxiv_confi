#!/usr/bin/env python3
"""
CSV íŒŒì¼ í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ìŠ¤í‚¤ë§ˆ JSON íŒŒì¼ ìƒì„±
ë‹¤ì–‘í•œ CSV íŒŒì¼ì— ëŒ€ì‘ ê°€ëŠ¥í•œ ì¼ë°˜í™”ëœ ìŠ¤í‚¤ë§ˆ ìƒì„±ê¸°
"""

import csv
import json
import os
import argparse
from pathlib import Path


def generate_schema_from_csv(csv_path, class_name=None, db_name=None, output_path=None, vectorize_fields=None):
    """CSV íŒŒì¼ í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ìƒì„±í•˜ê³  JSON íŒŒì¼ë¡œ ì €ì¥"""
    print("ğŸ“Š CSV í—¤ë” ë¶„ì„ ì¤‘...")
    
    # CSV íŒŒì¼ í—¤ë” ì½ê¸°
    with open(csv_path, 'r', encoding='utf-8') as file:
        csv_reader = csv.DictReader(file)
        headers = csv_reader.fieldnames
    
    print(f"ğŸ“‹ ë°œê²¬ëœ í—¤ë”: {headers}")
    
    # í´ë˜ìŠ¤ëª…ê³¼ DBëª… ìë™ ìƒì„±
    if class_name is None:
        csv_name = Path(csv_path).stem.replace('_schema', '').replace('_', '').title()
        class_name = f"{csv_name}Document"
    
    if db_name is None:
        csv_name = Path(csv_path).stem.replace('_schema', '')
        db_name = f"{csv_name}_db"
    
    print(f"ğŸ·ï¸ í´ë˜ìŠ¤ëª…: {class_name}")
    print(f"ğŸ·ï¸ DBëª…: {db_name}")
    
    # ë°ì´í„° íƒ€ì… ë§¤í•‘ (í™•ì¥ëœ íŒ¨í„´)
    type_mapping = {
        'date': ['date'],
        'time': ['date'],
        'created': ['date'],
        'modified': ['date'],
        'updated': ['date'],
        'size': ['number'],
        'number': ['number'],
        'count': ['number'],
        'amount': ['number'],
        'price': ['number'],
        'score': ['number'],
        'rating': ['number'],
        'id': ['text'],
        'uuid': ['text'],
        'hash': ['text'],
        'email': ['text'],
        'mail': ['text'],
        'file': ['text'],
        'path': ['text'],
        'url': ['text'],
        'uri': ['text'],
        'phone': ['text'],
        'address': ['text'],
        'location': ['text'],
        'category': ['text'],
        'type': ['text'],
        'status': ['text'],
        'state': ['text']
    }
    
    # ë²¡í„°í™”í•  í•„ë“œ ê²°ì •
    if vectorize_fields is None:
        # ê¸°ë³¸ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ë“¤ì–´ê°ˆ ë§Œí•œ í•„ë“œë“¤ì„ ë²¡í„°í™”
        default_vectorize_patterns = ['content', 'text', 'description', 'summary', 'body', 'message']
        vectorize_fields = []
    
    # ìŠ¤í‚¤ë§ˆ ì†ì„± ìƒì„±
    properties = []
    vectorizer_config = {}
    
    for header in headers:
        # í—¤ë”ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì¹˜í™˜
        field_name = header.lower().replace(' ', '_').replace('-', '_')
        
        # ë°ì´í„° íƒ€ì… ê²°ì •
        data_type = ['text']  # ê¸°ë³¸ê°’
        for keyword, type_val in type_mapping.items():
            if keyword in field_name.lower():
                data_type = type_val
                break
        
        # ì†ì„± ì •ì˜
        property_def = {
            "name": field_name,
            "dataType": data_type,
            "description": header
        }
        properties.append(property_def)
        
        # ë²¡í„°í™” ì„¤ì •
        should_vectorize = False
        if vectorize_fields:
            # ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ í•„ë“œë“¤
            should_vectorize = field_name in vectorize_fields
        else:
            # ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
            should_vectorize = any(pattern in field_name.lower() for pattern in ['content', 'text', 'description', 'summary', 'body', 'message'])
        
        vectorizer_config[field_name] = {"skip": not should_vectorize}
    
    # content í•„ë“œê°€ ì—†ìœ¼ë©´ ì¶”ê°€ (í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì½ì„ ë‚´ìš©ìš©)
    if 'content' not in [p['name'] for p in properties]:
        properties.append({
            "name": "content",
            "dataType": ["text"],
            "description": "Document Content"
        })
        vectorizer_config['content'] = {"skip": False}
    
    # ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ìƒì„±
    schema = {
        "class": class_name,
        "vectorizer": "text2vec-openai",
        "properties": properties,
        "moduleConfig": {
            "text2vec-openai": {
                "model": "/data/models_ckpt/bge-m3",
                "type": "text",
                "vectorizeClassName": False,
                "vectorizePropertyName": False,
                "properties": vectorizer_config
            }
        }
    }
    
    print(f"âœ… {len(properties)}ê°œ ì†ì„±ì„ ê°€ì§„ ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    if output_path is None:
        schema_name = Path(csv_path).stem.replace('_schema', '') + '_schema.json'
        output_path = Path(csv_path).parent / schema_name
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(schema, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì €ì¥: {output_path}")
    return schema, db_name


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="CSV íŒŒì¼ í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±")
    parser.add_argument("csv_path", help="CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--class-name", help="Weaviate í´ë˜ìŠ¤ëª… (ê¸°ë³¸ê°’: CSVíŒŒì¼ëª…+Document)")
    parser.add_argument("--db-name", help="ë°ì´í„°ë² ì´ìŠ¤ëª… (ê¸°ë³¸ê°’: CSVíŒŒì¼ëª…_db)")
    parser.add_argument("--output", help="ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--vectorize", nargs='+', help="ë²¡í„°í™”í•  í•„ë“œëª… ëª©ë¡")
    
    args = parser.parse_args()
    
    print("ğŸ—ï¸ ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±ê¸°")
    print("=" * 50)
    
    # CSV íŒŒì¼ ê²½ë¡œ í™•ì¸
    csv_path = Path(args.csv_path)
    if not csv_path.exists():
        print(f"âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
        return
    
    # ìŠ¤í‚¤ë§ˆ ìƒì„±
    schema, db_name = generate_schema_from_csv(
        csv_path=csv_path,
        class_name=args.class_name,
        db_name=args.db_name,
        output_path=args.output,
        vectorize_fields=args.vectorize
    )
    
    # ìƒì„±ëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶œë ¥
    print("\nğŸ“Š ìƒì„±ëœ ìŠ¤í‚¤ë§ˆ ì •ë³´:")
    print(f"   í´ë˜ìŠ¤ëª…: {schema['class']}")
    print(f"   DBëª…: {db_name}")
    print(f"   ë²¡í„°ë¼ì´ì €: {schema['vectorizer']}")
    print(f"   ì†ì„± ìˆ˜: {len(schema['properties'])}")
    
    print("\nğŸ“‹ ì†ì„± ëª©ë¡:")
    vectorized_count = 0
    for i, prop in enumerate(schema['properties'], 1):
        data_type = prop['dataType'][0]
        is_vectorized = not schema['moduleConfig']['text2vec-openai']['properties'][prop['name']]['skip']
        vectorized = "âœ…" if is_vectorized else "âŒ"
        if is_vectorized:
            vectorized_count += 1
        print(f"   {i:2d}. {prop['name']:<20} ({data_type:<8}) {vectorized} - {prop['description']}")
    
    print(f"\nğŸ“ˆ ë²¡í„°í™” í•„ë“œ ìˆ˜: {vectorized_count}/{len(schema['properties'])}")
    print("\nâœ… ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ!")


def generate_precedent_schema(output_path=None):
    """íŒë¡€ ë°ì´í„°ë¥¼ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ìƒì„±"""
    print("ğŸ“Š íŒë¡€ ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
    
    # íŒë¡€ ìŠ¤í‚¤ë§ˆ ì •ì˜
    schema = {
        "class": "Precedent",
        "vectorizer": "text2vec-openai",
        "properties": [
            {"name": "text", "dataType": ["text"], "description": "íŒë¡€ ë‚´ìš©"},
            {"name": "documentId", "dataType": ["int"], "description": "ë¬¸ì„œ ID"},
            {"name": "documentName", "dataType": ["text"], "description": "ì‚¬ê±´ëª…"},
            {"name": "documentType", "dataType": ["text"], "description": "ì‚¬ê±´ ìœ í˜•"},
            {"name": "source", "dataType": ["text"], "description": "ì¶œì²˜"}
        ],
        "moduleConfig": {
            "text2vec-openai": {
                "model": "/data/models_ckpt/bge-m3",
                "type": "text",
                "vectorizeClassName": False,
                "vectorizePropertyName": False,
                "properties": {
                    "text": {"skip": False},
                    "documentId": {"skip": True},
                    "documentName": {"skip": True},
                    "documentType": {"skip": True},
                    "source": {"skip": True}
                }
            }
        }
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    if output_path is None:
        output_path = Path(__file__).parent / "../schema_examples/precedent_schema.json"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(schema, f, ensure_ascii=False, indent=4)
    
    print(f"ğŸ“„ íŒë¡€ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì €ì¥: {output_path}")
    return schema


if __name__ == "__main__":
    main()