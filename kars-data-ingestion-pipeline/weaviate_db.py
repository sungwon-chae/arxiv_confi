import logging
import os
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime
import re
import weaviate
from weaviate.classes.config import Property, DataType, Configure, VectorDistances
from weaviate.classes.query import Filter, MetadataQuery
from openai import OpenAI
from dotenv import load_dotenv
from base import VectorDB, VectorDBConfig

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = Path(__file__).parent / 'config.env'
load_dotenv(env_path)

logger = logging.getLogger(__name__)

def normalize_date_to_rfc3339(date_str: str) -> str:
    """ë‚ ì§œ ë¬¸ìì—´ì„ RFC3339 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str or date_str.strip() == "":
        return "1970-01-01T00:00:00Z"  # ê¸°ë³¸ê°’
    
    try:
        # ì´ë¯¸ RFC3339 í˜•ì‹ì¸ì§€ í™•ì¸
        if re.match(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z?', date_str):
            if not date_str.endswith('Z'):
                date_str += 'Z'
            return date_str
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒŒì‹± ì‹œë„
        formats = [
            "%Y-%m-%d %H:%M",      # 2000-07-10 23:47
            "%Y-%m-%d %H:%M:%S",   # 2000-07-10 23:47:00
            "%Y-%m-%d",            # 2000-07-10
            "%m/%d/%Y",            # 07/10/2000
            "%m/%d/%Y %H:%M",      # 07/10/2000 23:47
            "%d/%m/%Y",            # 10/07/2000
            "%Y%m%d",              # 20000710
        ]
        
        for fmt in formats:
            try:
                dt = datetime.strptime(date_str, fmt)
                return dt.strftime("%Y-%m-%dT%H:%M:%SZ")
            except ValueError:
                continue
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        logger.warning(f"ë‚ ì§œ í˜•ì‹ íŒŒì‹± ì‹¤íŒ¨: {date_str}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return "1970-01-01T00:00:00Z"
        
    except Exception as e:
        logger.warning(f"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return "1970-01-01T00:00:00Z"

class WeaviateDB(VectorDB):
    """Weaviate ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬í˜„ì²´ (test_openai_vectorizer.py ë°©ì‹ ì™„ì „ ì ìš©)"""
    
    def __init__(self, config: VectorDBConfig):
        super().__init__(config)
        self.client = None
        self.openai_client = None
        self.dynamic_model_name = None
        
    async def initialize(self):
        """ì´ˆê¸°í™” (test_openai_vectorizer.py ë°©ì‹ ê·¸ëŒ€ë¡œ)"""
        try:
            # 1. ë¨¼ì € OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ëª¨ë¸ëª… ë™ì  ê°€ì ¸ì˜¤ê¸°
            openai_api_key = self.config.connection_params.get('openai_api_key', os.getenv('OPENAI_API_KEY', 'token-abc123'))
            openai_base_url_with_v1 = self.config.connection_params.get('openai_base_url', os.getenv('OPENAI_BASE_URL', 'http://localhost:8125'))
            
            # /v1 suffixê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ë‹¤ì‹œ ì¶”ê°€ (ì¼ê´€ì„± ë³´ì¥)
            if openai_base_url_with_v1.endswith('/v1'):
                openai_base_url_with_v1 = openai_base_url_with_v1[:-3]
            openai_base_url_with_v1 += '/v1'
            
            self.openai_client = OpenAI(
                api_key=openai_api_key,
                base_url=openai_base_url_with_v1
            )
            
            # vLLM ì„œë²„ì—ì„œ ëª¨ë¸ëª… ë™ì  ê°€ì ¸ì˜¤ê¸° (test_openai_vectorizer.py ë°©ì‹)
            try:
                models = self.openai_client.models.list()
                if models.data:
                    self.dynamic_model_name = models.data[0].id
                    logger.info(f"âœ… vLLM ì„œë²„ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜´: {self.dynamic_model_name}")
                else:
                    self.dynamic_model_name = self.config.embedding_model
                    logger.warning(f"âš ï¸ vLLM ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ì´ ë¹„ì–´ìˆìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©: {self.dynamic_model_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ vLLM ì„œë²„ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                self.dynamic_model_name = self.config.embedding_model

            # 2. ìƒ˜í”Œ ì„ë² ë”© ìƒì„± í™•ì¸ (test_openai_vectorizer.py ë°©ì‹)
            try:
                sample_text = "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"
                response = self.openai_client.embeddings.create(
                    input=[sample_text],
                    model=self.dynamic_model_name,
                )
                embedding = response.data[0].embedding
                logger.info(f"âœ… ìƒ˜í”Œ ì„ë² ë”© ìƒì„± ì„±ê³µ (ì°¨ì›: {len(embedding)})")
            except Exception as e:
                logger.error(f"âŒ ìƒ˜í”Œ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                raise

            # 3. Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
            url = self.config.connection_params.get('url', os.getenv('WEAVIATE_URL', 'http://localhost:8084'))
            
            # URLì—ì„œ í˜¸ìŠ¤íŠ¸ì™€ í¬íŠ¸ ì¶”ì¶œ
            if '://' in url:
                protocol, host_port = url.split('://', 1)
                if ':' in host_port:
                    host, port = host_port.split(':', 1)
                    port = int(port)
                else:
                    host = host_port
                    port = int(os.getenv('WEAVIATE_PORT', '8084'))
            else:
                host = os.getenv('WEAVIATE_HOST', 'localhost')
                port = int(os.getenv('WEAVIATE_PORT', '8084'))
            
            # OpenAI í—¤ë” ì„¤ì • (test_openai_vectorizer.py ë°©ì‹ - /v1 ì œê±°)
            # Weaviate ì»¨í…Œì´ë„ˆì—ì„œ í˜¸ìŠ¤íŠ¸ì˜ vLLM ì„œë²„ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ host.docker.internal ì‚¬ìš©
            openai_base_url_for_weaviate = openai_base_url_with_v1.replace('localhost', 'host.docker.internal').replace('/v1', '')
            headers = {
                "X-OpenAI-Api-Key": openai_api_key, 
                "X-OpenAI-BaseURL": openai_base_url_for_weaviate  # Weaviate expects URL without /v1
            }
            
            # gRPC í¬íŠ¸ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            grpc_port = int(os.getenv('WEAVIATE_GRPC_PORT', '50051'))
            
            # ì›ê²© ì„œë²„ ì—°ê²°ì„ ìœ„í•´ connect_to_local ëŒ€ì‹  weaviate.connect_to_custom ì‚¬ìš©
            if host == 'localhost' or host == '127.0.0.1':
                self.client = weaviate.connect_to_local(
                    host=host,
                    port=port,
                    grpc_port=grpc_port,
                    headers=headers
                )
            else:
                # ì›ê²© ì„œë²„ ì—°ê²°
                self.client = weaviate.connect_to_custom(
                    http_host=host,
                    http_port=port,
                    http_secure=False,
                    grpc_host=host,
                    grpc_port=grpc_port,
                    grpc_secure=False,
                    headers=headers
                )
            
            logger.info(f"âœ… Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ: {url}")
            logger.info(f"ğŸ“¡ OpenAI Base URL (Pythonìš©): {openai_base_url_with_v1}")
            logger.info(f"ğŸ“¡ OpenAI Base URL (Weaviateìš©): {headers['X-OpenAI-BaseURL']}")
            logger.info(f"ğŸ”§ ë™ì  ëª¨ë¸ëª…: {self.dynamic_model_name}")
            
        except Exception as e:
            logger.error(f"âŒ Weaviate ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def create_schema(self, schema_definition: Dict[str, Any]) -> bool:
        """ìŠ¤í‚¤ë§ˆ ìƒì„± (ë™ì  ëª¨ë¸ëª… ì‚¬ìš©, test_openai_vectorizer.py ë°©ì‹)"""
        try:
            class_name = schema_definition.get("class", "Document")
            
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
            if self.client.collections.exists(class_name):
                self.client.collections.delete(class_name)
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {class_name}")
            
            # ì†ì„± ì •ì˜
            properties = []
            for prop in schema_definition.get("properties", []):
                prop_name = prop["name"]
                prop_type = prop.get("dataType", ["text"])[0].upper()
                
                # ë°ì´í„° íƒ€ì… ë§¤í•‘
                if prop_type == "TEXT":
                    data_type = DataType.TEXT
                elif prop_type == "INT":
                    data_type = DataType.INT
                elif prop_type == "NUMBER":
                    data_type = DataType.NUMBER
                elif prop_type == "BOOLEAN":
                    data_type = DataType.BOOL
                elif prop_type == "DATE":
                    data_type = DataType.DATE
                else:
                    data_type = DataType.TEXT
                
                properties.append(Property(name=prop_name, data_type=data_type))
            
            # ë²¡í„°ë¼ì´ì € ì„¤ì •ì—ì„œ ë™ì  ëª¨ë¸ëª… ì‚¬ìš© (test_openai_vectorizer.py ë°©ì‹)
            # Weaviate ì»¨í…Œì´ë„ˆì—ì„œ í˜¸ìŠ¤íŠ¸ì˜ vLLM ì„œë²„ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ host.docker.internal ì‚¬ìš©
            openai_base_url_raw = self.config.connection_params.get('openai_base_url', os.getenv('OPENAI_BASE_URL', 'http://localhost:8125'))
            # Docker ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•  URL (ì»¨í…Œì´ë„ˆì—ì„œ í˜¸ìŠ¤íŠ¸ ì ‘ê·¼ìš©)
            openai_base_url_for_weaviate = os.getenv('OPENAI_BASE_URL_DOCKER', openai_base_url_raw.replace('localhost', 'host.docker.internal'))
            if openai_base_url_for_weaviate.endswith('/v1'):
                openai_base_url_for_weaviate = openai_base_url_for_weaviate[:-3]
            
            vectorizer = Configure.Vectorizer.text2vec_openai(
                model=self.dynamic_model_name,  # ë™ì  ëª¨ë¸ëª… ì‚¬ìš©
                base_url=openai_base_url_for_weaviate  # /v1 ì œê±°ëœ URL ì‚¬ìš©
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„± (test_openai_vectorizer.py ë°©ì‹)
            collection = self.client.collections.create(
                name=class_name,
                properties=properties,
                vectorizer_config=vectorizer,
                vector_index_config=Configure.VectorIndex.hnsw(
                    distance_metric=VectorDistances.COSINE
                )
            )
            
            logger.info(f"âœ… ìŠ¤í‚¤ë§ˆ ìƒì„± ì„±ê³µ: {class_name} (ëª¨ë¸: {self.dynamic_model_name})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    async def get_schema(self) -> Dict[str, Any]:
        """Weaviate ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
        try:
            # Weaviate v4 clientë¥¼ ì‚¬ìš©í•´ì„œ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
            schema_data = {"classes": []}
            
            # ëª¨ë“  ì»¬ë ‰ì…˜ ì¡°íšŒ
            for collection_name in self.client.collections.list_all():
                try:
                    collection = self.client.collections.get(collection_name)
                    collection_config = collection.config.get()
                    
                    # í´ë˜ìŠ¤ ì •ë³´ êµ¬ì„±
                    class_info = {
                        "class": collection_name,
                        "vectorizer": collection_config.vectorizer_config.vectorizer.value if collection_config.vectorizer_config else None,
                        "properties": []
                    }
                    
                    # ì†ì„± ì •ë³´ ì¶”ê°€
                    if hasattr(collection_config, 'properties') and collection_config.properties:
                        if hasattr(collection_config.properties, 'items'):
                            # Dict-like properties
                            for prop_name, prop_config in collection_config.properties.items():
                                prop_info = {
                                    "name": prop_name,
                                    "dataType": [prop_config.data_type.value] if prop_config.data_type else ["text"]
                                }
                                class_info["properties"].append(prop_info)
                        elif isinstance(collection_config.properties, list):
                            # List-like properties
                            for prop_config in collection_config.properties:
                                if hasattr(prop_config, 'name'):
                                    prop_info = {
                                        "name": prop_config.name,
                                        "dataType": [prop_config.data_type.value] if hasattr(prop_config, 'data_type') and prop_config.data_type else ["text"]
                                    }
                                    class_info["properties"].append(prop_info)
                    
                    schema_data["classes"].append(class_info)
                    
                except Exception as e:
                    logger.warning(f"ì»¬ë ‰ì…˜ {collection_name} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì™„ë£Œ: {len(schema_data['classes'])}ê°œ í´ë˜ìŠ¤")
            return schema_data
            
        except Exception as e:
            logger.error(f"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"classes": []}

    async def insert_documents(self, documents: List[Dict[str, Any]], class_name: str = None, 
                              vectorize_fields: List[str] = None) -> List[str]:
        """ë¬¸ì„œ ì‚½ì… (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ìë™ ë²¡í„°í™” + ì„ íƒì  í•„ë“œ ë²¡í„°í™”)"""
        if not class_name:
            class_name = self.config.default_class
        
        try:
            collection = self.client.collections.get(class_name)
            inserted_ids = []
            
            # ë²¡í„°í™” í•„ë“œ ë¡œê¹…
            if vectorize_fields:
                logger.info(f"ğŸ“ ìˆ˜ë™ ë²¡í„°í™” í•„ë“œ ì§€ì •: {vectorize_fields}")
            else:
                logger.info(f"ğŸ“ ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ìë™ ë²¡í„°í™” ì‚¬ìš© (moduleConfig ê¸°ë°˜)")
            
            # ë°°ì¹˜ ì‚½ì…
            with collection.batch.dynamic() as batch:
                for i, doc in enumerate(documents):
                    try:
                        # ë‚ ì§œ í•„ë“œ ì •ê·œí™”
                        normalized_doc = self._normalize_document_dates(doc)
                        
                        # ë²¡í„°í™” í•„ë“œê°€ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš° ì²˜ë¦¬
                        if vectorize_fields:
                            # ëª…ì‹œëœ í•„ë“œë“¤ë§Œ ë²¡í„°í™”ìš© í…ìŠ¤íŠ¸ ìƒì„±
                            vectorize_text = self._create_vectorize_text(normalized_doc, vectorize_fields)
                            logger.debug(f"ë¬¸ì„œ {i+1} ë²¡í„°í™” í…ìŠ¤íŠ¸: {vectorize_text[:100]}...")
                            
                            # ìˆ˜ë™ ì„ë² ë”© ìƒì„±
                            try:
                                response = self.openai_client.embeddings.create(
                                    input=[vectorize_text],
                                    model=self.dynamic_model_name,
                                )
                                vector = response.data[0].embedding
                                logger.debug(f"ë¬¸ì„œ {i+1} ì„ë² ë”© ìƒì„± ì„±ê³µ (ì°¨ì›: {len(vector)})")
                            except Exception as e:
                                logger.warning(f"ë¬¸ì„œ {i+1} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}, ìë™ ë²¡í„°í™”ë¡œ ëŒ€ì²´")
                                vector = None
                        else:
                            # ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ìë™ ë²¡í„°í™” (ê¸°ì¡´ ë°©ì‹)
                            vector = None
                        
                        # ë¬¸ì„œ ì‚½ì…
                        uuid = batch.add_object(properties=normalized_doc, vector=vector)
                        if uuid:
                            inserted_ids.append(str(uuid))
                            
                    except Exception as e:
                        logger.error(f"ë¬¸ì„œ {i+1} ì‚½ì… ì‹¤íŒ¨: {e}")
                        continue
            
            logger.info(f"âœ… {len(inserted_ids)}ê°œ ë¬¸ì„œ ì‚½ì… ì™„ë£Œ: {class_name}")
            if vectorize_fields:
                logger.info(f"ğŸ“Š ë²¡í„°í™” í•„ë“œ: {vectorize_fields}")
            
            return inserted_ids
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì‚½ì… ì‹¤íŒ¨: {e}")
            return []
    
    def _create_vectorize_text(self, doc: Dict[str, Any], vectorize_fields: List[str]) -> str:
        """ì§€ì •ëœ í•„ë“œë“¤ë¡œë¶€í„° ë²¡í„°í™”ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
        texts = []
        
        for field in vectorize_fields:
            if field in doc:
                value = doc[field]
                if isinstance(value, str):
                    texts.append(value)
                elif isinstance(value, (list, tuple)):
                    texts.extend([str(item) for item in value])
                else:
                    texts.append(str(value))
        
        combined_text = " ".join(texts).strip()
        return combined_text if combined_text else "ë¹ˆ ë¬¸ì„œ"
    
    def _normalize_document_dates(self, doc: Dict[str, Any]) -> Dict[str, Any]:
        """ë¬¸ì„œì˜ ë‚ ì§œ í•„ë“œë¥¼ RFC3339 í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
        normalized_doc = doc.copy()
        
        # ë‚ ì§œ í•„ë“œë¡œ ì¶”ì •ë˜ëŠ” í•„ë“œëª… íŒ¨í„´
        date_field_patterns = [
            'date', 'time', 'created', 'updated', 'published', 'modified',
            'sent', 'received', 'sort_date', 'publish_date', 'create_date'
        ]
        
        for field_name, value in normalized_doc.items():
            # í•„ë“œëª…ì´ ë‚ ì§œ ê´€ë ¨ íŒ¨í„´ì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
            is_date_field = any(pattern in field_name.lower() for pattern in date_field_patterns)
            
            if is_date_field and isinstance(value, str) and value.strip():
                try:
                    normalized_doc[field_name] = normalize_date_to_rfc3339(value)
                    logger.debug(f"ë‚ ì§œ í•„ë“œ '{field_name}' ì •ê·œí™”: {value} -> {normalized_doc[field_name]}")
                except Exception as e:
                    logger.warning(f"ë‚ ì§œ í•„ë“œ '{field_name}' ì •ê·œí™” ì‹¤íŒ¨: {e}")
                    # ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                    normalized_doc[field_name] = "1970-01-01T00:00:00Z"
        
        return normalized_doc

    async def search(self, query: str, class_name: str = None, limit: int = 5, 
                    filters: Optional[Dict[str, Any]] = None, hybrid: bool = False) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ì§€ëŠ¥ì  í•„í„°ë§ ì§€ì›)"""
        if not class_name:
            class_name = self.config.default_class
        
        try:
            collection = self.client.collections.get(class_name)
            
            # í•„í„° ì²˜ë¦¬ - ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í™œìš©í•œ ì§€ëŠ¥ì  í•„í„°ë§
            filter_obj = None
            if filters:
                filter_obj = await self._build_smart_filter(filters, class_name)
            
            # ê²€ìƒ‰ ì‹¤í–‰ (test_openai_vectorizer.py ë°©ì‹)
            if hybrid:
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
                response = collection.query.hybrid(
                    query=query,
                    filters=filter_obj,
                    limit=limit,
                    return_metadata=MetadataQuery(distance=True, score=True)
                )
            else:
                # ë²¡í„° ê²€ìƒ‰
                response = collection.query.near_text(
                    query=query,
                    filters=filter_obj,
                    limit=limit,
                    return_metadata=MetadataQuery(distance=True)
                )
            
            # ê²°ê³¼ ë³€í™˜ (test_openai_vectorizer.py ë°©ì‹)
            results = []
            for obj in response.objects:
                result = {
                    "id": str(obj.uuid),
                    "properties": obj.properties,
                    "distance": getattr(obj.metadata, 'distance', 0.0),
                    "score": getattr(obj.metadata, 'score', 0.0)
                }
                results.append(result)
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ (ì¿¼ë¦¬: '{query}'")
            if filter_obj:
                logger.info(f"ğŸ“Š í•„í„° ì ìš©ë¨: {filters}")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _build_smart_filter(self, filters: Dict[str, Any], class_name: str) -> Optional[object]:
        """ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í™œìš©í•œ ì§€ëŠ¥ì  í•„í„° êµ¬ì„±"""
        try:
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ
            schema_data = await self.get_schema()
            class_schema = None
            
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ìŠ¤í‚¤ë§ˆ ì°¾ê¸°
            for class_info in schema_data.get('classes', []):
                if class_info['class'] == class_name:
                    class_schema = class_info
                    break
            
            if not class_schema:
                logger.warning(f"í´ë˜ìŠ¤ '{class_name}' ìŠ¤í‚¤ë§ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return self._build_basic_filter(filters)
            
            # ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ í•„í„° êµ¬ì„±
            filter_conditions = []
            
            for field_name, filter_value in filters.items():
                # ìŠ¤í‚¤ë§ˆì—ì„œ í•´ë‹¹ í•„ë“œ ì •ë³´ ì°¾ê¸°
                field_info = self._find_field_in_schema(field_name, class_schema)
                
                if field_info:
                    field_filter = self._create_field_filter(field_name, filter_value, field_info)
                    if field_filter:
                        filter_conditions.append(field_filter)
                else:
                    logger.warning(f"í•„ë“œ '{field_name}'ì´ ìŠ¤í‚¤ë§ˆì— ì—†ìŒ, ê¸°ë³¸ í•„í„° ì ìš©")
                    # ìŠ¤í‚¤ë§ˆì— ì—†ëŠ” í•„ë“œë„ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                    basic_filter = self._create_basic_field_filter(field_name, filter_value)
                    if basic_filter:
                        filter_conditions.append(basic_filter)
            
            # ì—¬ëŸ¬ ì¡°ê±´ì„ ANDë¡œ ê²°í•©
            if len(filter_conditions) == 1:
                return filter_conditions[0]
            elif len(filter_conditions) > 1:
                combined_filter = filter_conditions[0]
                for condition in filter_conditions[1:]:
                    combined_filter = combined_filter & condition
                return combined_filter
            
            return None
            
        except Exception as e:
            logger.error(f"ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ í•„í„° êµ¬ì„± ì‹¤íŒ¨: {e}")
            return self._build_basic_filter(filters)
    
    def _find_field_in_schema(self, field_name: str, class_schema: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ìŠ¤í‚¤ë§ˆì—ì„œ í•„ë“œ ì •ë³´ ì°¾ê¸°"""
        for prop in class_schema.get('properties', []):
            if prop['name'] == field_name:
                return prop
        return None
    
    def _create_field_filter(self, field_name: str, filter_value: Any, field_info: Dict[str, Any]) -> Optional[object]:
        """í•„ë“œ íƒ€ì…ì— ë§ëŠ” í•„í„° ìƒì„±"""
        try:
            data_type = field_info.get('dataType', ['text'])[0].lower()
            
            if isinstance(filter_value, dict):
                # ì—°ì‚°ì ê¸°ë°˜ í•„í„° (gt, lt, eq, gte, lte, between)
                if "between" in filter_value:
                    return self._create_between_filter(field_name, filter_value["between"], data_type)
                elif "after" in filter_value or "gt" in filter_value:
                    value = filter_value.get("after", filter_value.get("gt"))
                    return self._create_comparison_filter(field_name, value, "gt", data_type)
                elif "before" in filter_value or "lt" in filter_value:
                    value = filter_value.get("before", filter_value.get("lt"))
                    return self._create_comparison_filter(field_name, value, "lt", data_type)
                elif "gte" in filter_value:
                    return self._create_comparison_filter(field_name, filter_value["gte"], "gte", data_type)
                elif "lte" in filter_value:
                    return self._create_comparison_filter(field_name, filter_value["lte"], "lte", data_type)
                elif "eq" in filter_value:
                    return self._create_comparison_filter(field_name, filter_value["eq"], "eq", data_type)
                elif "contains" in filter_value:
                    return Filter.by_property(field_name).contains_any([filter_value["contains"]])
            else:
                # ì§ì ‘ ê°’ ë¹„êµ
                return self._create_comparison_filter(field_name, filter_value, "eq", data_type)
            
            return None
            
        except Exception as e:
            logger.error(f"í•„ë“œ '{field_name}' í•„í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_comparison_filter(self, field_name: str, value: Any, operator: str, data_type: str) -> Optional[object]:
        """ë¹„êµ ì—°ì‚°ì í•„í„° ìƒì„±"""
        try:
            # ë‚ ì§œ íƒ€ì… ì²˜ë¦¬
            if data_type == "date" or self._is_date_field(field_name):
                if isinstance(value, str):
                    value = normalize_date_to_rfc3339(value)
            
            # ì—°ì‚°ìë³„ í•„í„° ìƒì„±
            if operator == "gt" or operator == "after":
                return Filter.by_property(field_name).greater_than(value)
            elif operator == "gte":
                return Filter.by_property(field_name).greater_or_equal(value)
            elif operator == "lt" or operator == "before":
                return Filter.by_property(field_name).less_than(value)
            elif operator == "lte":
                return Filter.by_property(field_name).less_or_equal(value)
            elif operator == "eq":
                return Filter.by_property(field_name).equal(value)
            
            return None
            
        except Exception as e:
            logger.error(f"ë¹„êµ í•„í„° ìƒì„± ì‹¤íŒ¨ ({field_name} {operator} {value}): {e}")
            return None
    
    def _create_between_filter(self, field_name: str, between_value: Any, data_type: str) -> Optional[object]:
        """ë²”ìœ„ í•„í„° ìƒì„± (between)"""
        try:
            if isinstance(between_value, str):
                # "2024-01-01,2024-12-31" í˜•íƒœ íŒŒì‹±
                parts = between_value.split(',')
                if len(parts) != 2:
                    logger.error(f"between ê°’ í˜•ì‹ ì˜¤ë¥˜: {between_value}")
                    return None
                start_value, end_value = parts[0].strip(), parts[1].strip()
            elif isinstance(between_value, list) and len(between_value) == 2:
                start_value, end_value = between_value
            else:
                logger.error(f"between ê°’ íƒ€ì… ì˜¤ë¥˜: {between_value}")
                return None
            
            # ë‚ ì§œ íƒ€ì… ì²˜ë¦¬
            if data_type == "date" or self._is_date_field(field_name):
                start_value = normalize_date_to_rfc3339(str(start_value))
                end_value = normalize_date_to_rfc3339(str(end_value))
            
            # ë²”ìœ„ í•„í„°: start_value <= field <= end_value
            return (Filter.by_property(field_name).greater_or_equal(start_value) & 
                   Filter.by_property(field_name).less_or_equal(end_value))
            
        except Exception as e:
            logger.error(f"ë²”ìœ„ í•„í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _is_date_field(self, field_name: str) -> bool:
        """í•„ë“œëª…ì´ ë‚ ì§œ ê´€ë ¨ì¸ì§€ í™•ì¸"""
        date_patterns = [
            'date', 'time', 'created', 'updated', 'published', 'modified',
            'sent', 'received', 'sort_date', 'publish_date', 'create_date'
        ]
        return any(pattern in field_name.lower() for pattern in date_patterns)
    
    def _create_basic_field_filter(self, field_name: str, filter_value: Any) -> Optional[object]:
        """ê¸°ë³¸ í•„ë“œ í•„í„° ìƒì„± (ìŠ¤í‚¤ë§ˆ ì •ë³´ ì—†ì„ ë•Œ)"""
        try:
            if isinstance(filter_value, dict):
                if "gt" in filter_value:
                    return Filter.by_property(field_name).greater_than(filter_value["gt"])
                elif "lt" in filter_value:
                    return Filter.by_property(field_name).less_than(filter_value["lt"])
                elif "eq" in filter_value:
                    return Filter.by_property(field_name).equal(filter_value["eq"])
            else:
                return Filter.by_property(field_name).equal(filter_value)
            return None
        except Exception as e:
            logger.error(f"ê¸°ë³¸ í•„í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _build_basic_filter(self, filters: Dict[str, Any]) -> Optional[object]:
        """ê¸°ë³¸ í•„í„° êµ¬ì„± (ê¸°ì¡´ ë°©ì‹)"""
        filter_obj = None
        for field, value in filters.items():
            current_filter = self._create_basic_field_filter(field, value)
            if current_filter:
                if filter_obj is None:
                    filter_obj = current_filter
                else:
                    filter_obj = filter_obj & current_filter
        return filter_obj

    async def get_document_by_id(self, doc_id: str, class_name: str = None) -> Optional[Dict[str, Any]]:
        """IDë¡œ ë¬¸ì„œ ì¡°íšŒ (test_openai_vectorizer.py ë°©ì‹)"""
        if not class_name:
            class_name = self.config.default_class
        
        try:
            collection = self.client.collections.get(class_name)
            
            # UUIDë¡œ ë¬¸ì„œ ì¡°íšŒ (test_openai_vectorizer.py ë°©ì‹)
            retrieved_obj = collection.query.fetch_object_by_id(doc_id)
            
            if retrieved_obj:
                document = {
                    "id": str(retrieved_obj.uuid),
                    "properties": retrieved_obj.properties,
                    "class_name": class_name
                }
                logger.info(f"ğŸ“„ ë¬¸ì„œ ì¡°íšŒ ì„±ê³µ: {doc_id}")
                return document
            else:
                logger.warning(f"âš ï¸ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {doc_id} (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)")
                return None
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def close(self):
        """ì—°ê²° ì¢…ë£Œ (test_openai_vectorizer.py ë°©ì‹)"""
        try:
            if self.client:
                self.client.close()
                logger.info("âœ… Weaviate í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}") 