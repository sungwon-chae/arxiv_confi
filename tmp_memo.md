"""
Weaviate MCP ë„êµ¬ í´ë˜ìŠ¤

kars_db.pyì˜ RAGVectorDBë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from openai import OpenAI
from kars_db import RAGVectorDB
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

# ì´ë¦„ ìˆ˜ì • ê¸°ëŠ¥ ì‚¬ìš© ì—¬ë¶€
USE_NAME_REVISION = os.getenv("USE_NAME_REVISION", "true").lower() == "true"


class FilterExtractionResult(BaseModel):
    custodian: Optional[str] = Field(None, description="ë³´ê´€ì")
    ori_file_name: Optional[str] = Field(None, description="ì›ë³¸ íŒŒì¼ëª…")
    s_created_date: Optional[Union[str, Dict[str, Any]]] = Field(None, description="ìƒì„±ì¼")
    # s_modified_date: Optional[str] = Field(None, description="ìˆ˜ì •ì¼")
    sent_date: Optional[Union[str, Dict[str, Any]]] = Field(None, description="ë°œì†¡ì¼")
    from_email: Optional[str] = Field(None, description="ë°œì‹ ì ì´ë©”ì¼")
    to_email: Optional[str] = Field(None, description="ìˆ˜ì‹ ì ì´ë©”ì¼")
    cc: Optional[str] = Field(None, description="ì°¸ì¡° ì´ë©”ì¼")
    bcc: Optional[str] = Field(None, description="ìˆ¨ì€ì°¸ì¡° ì´ë©”ì¼")
    last_author: Optional[str] = Field(None, description="ìµœì¢… ì‘ì„±ì")
    extension: Optional[str] = Field(None, description="íŒŒì¼ í™•ì¥ì")
    


class WeaviateMCPTools:
    """Weaviate MCP ë„êµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.rag_db: Optional[RAGVectorDB] = None
        self.initialized = False
        self.default_db_name = os.getenv("WEAVIATE_DB_NAME", "kars_test")
        base_url="http://10.10.190.1:8124/v1"
        api_key="token-abc123"
        self.client = OpenAI(base_url=base_url, api_key=api_key)
        
        
        # ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œ ë§¤í•‘ ì •ì˜ (FilterExtractionResultì— ë§ê²Œ ì¡°ì •)
        self.db_fields = {
            "custodian": "ë³´ê´€ì",
            "ori_file_name": "ì›ë³¸ íŒŒì¼ëª…",
            "s_created_date": "ìƒì„±ì¼",
            "sent_date": "ë°œì†¡ì¼",
            "from_email": "ë°œì‹ ì ì´ë©”ì¼",
            "to_email": "ìˆ˜ì‹ ì ì´ë©”ì¼",
            "cc": "ì°¸ì¡° ì´ë©”ì¼",
            "bcc": "ìˆ¨ì€ì°¸ì¡° ì´ë©”ì¼",
            "last_author": "ìµœì¢… ì‘ì„±ì",
            "extension": "íŒŒì¼ í™•ì¥ì"
        }
        

        logger.info("Weaviate MCP ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize_rag_db(self, db_name: str = None) -> bool:
        """RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""

        try:
            db_name = db_name or self.default_db_name
            self.rag_db = RAGVectorDB(db_name)
            success = await self.rag_db.initialize()
            
            if success:
                self.initialized = True
                logger.info(f"âœ… RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ: {db_name}")
                return True
            else:
                logger.error(f"âŒ RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {db_name}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    async def search_documents(self, query: str, filters: Optional[Dict[str, Any]] = None, 
                             sort_by_date: bool = False, limit: int = 5, 
                             db_name: str = None) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´
            filters: ë©”íƒ€ë°ì´í„° í•„í„° ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ë‹¨ìˆœ RAG ê²€ìƒ‰)
            sort_by_date: ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)
            db_name: ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” kars_test)
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹¤ë¥¸ DBë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš° ì¬ì´ˆê¸°í™”
            if not self.initialized or (db_name and db_name != self.default_db_name):
                if not await self.initialize_rag_db(db_name):
                    return {
                        "success": False,
                        "error": "ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                        "results": []
                    }
            
            if not self.rag_db:
                return {
                    "success": False,
                    "error": "RAG ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "results": []
                }
            
            # í•„í„°ê°€ ëª¨ë‘ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ë‹¨ìˆœ RAG ê²€ìƒ‰
            if not filters or all(v is None for v in filters.values()):
                logger.info(f"ğŸ” ë‹¨ìˆœ RAG ê²€ìƒ‰ ì‹¤í–‰: '{query}' (limit: {limit})")
                results = await self.rag_db.search_chunks(query, limit=limit)
            else:
                # í•„í„°ê°€ ìˆëŠ” ê²½ìš° í•„í„°ì™€ í•¨ê»˜ ê²€ìƒ‰
                logger.info(f"ğŸ” í•„í„° ê²€ìƒ‰ ì‹¤í–‰: '{query}' (í•„í„°: {filters}, limit: {limit})")
                results = await self.rag_db.search_with_metadata_filter(query, filters, limit=limit)
            
            if results:
                # ê²°ê³¼ í¬ë§·íŒ…
                formatted_results = []
                for result in results:
                    formatted_result = {
                        "id": result.get("id", ""),
                        "score": result.get("score", 0.0),
                        "content": result.get("properties", {}).get("chunk", ""),
                        "properties": result.get("properties", {})
                    }
                    formatted_results.append(formatted_result)
                
                # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ (sort_by_dateê°€ Trueì¸ ê²½ìš°)
                if sort_by_date:
                    formatted_results.sort(key=lambda x: self._parse_date_for_sorting(
                        x["properties"].get("sent_date") or 
                        x["properties"].get("s_created_date")
                    ))
                
                return {
                    "success": True,
                    "query": query,
                    "filters": filters,
                    "sort_by_date": sort_by_date,
                    "total_results": len(formatted_results),
                    "results": formatted_results,
                    "search_timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": True,
                    "query": query,
                    "filters": filters,
                    "sort_by_date": sort_by_date,
                    "total_results": 0,
                    "results": [],
                    "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "search_timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "success": False,
                "error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "results": []
            }
    
    async def get_document_with_filter(self, class_name: str, limit: int, 
                                     filters: Optional[Dict[str, Any]] = None,
                                     db_name: str = None, sort_by_date=True) -> Dict[str, Any]:
        """
        íŠ¹ì • í´ë˜ìŠ¤ì—ì„œ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            class_name: ê²€ìƒ‰í•  í´ë˜ìŠ¤ ì´ë¦„ (í•„ìˆ˜)
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (í•„ìˆ˜)
            filters: ë©”íƒ€ë°ì´í„° í•„í„° ë”•ì…”ë„ˆë¦¬ (ì„ íƒì‚¬í•­, Noneì´ë©´ ëª¨ë“  ë¬¸ì„œ ë°˜í™˜)
            db_name: ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹¤ë¥¸ DBë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš° ì¬ì´ˆê¸°í™”
            if not self.initialized or (db_name and db_name != self.default_db_name):
                if not await self.initialize_rag_db(db_name):
                    return {
                        "success": False,
                        "error": "ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                        "results": []
                    }
            
            if not self.rag_db:
                return {
                    "success": False,
                    "error": "RAG ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "results": []
                }
            
            # í•„í„° ê²€ìƒ‰ ì‹¤í–‰
            logger.info(f"ğŸ” í•„í„° ê²€ìƒ‰ ì‹¤í–‰: class_name={class_name}, limit={limit}, filters={filters}")
            results = await self.rag_db.get_document_with_filter(class_name, limit, filters)
            
            if results:
                # ê²°ê³¼ í¬ë§·íŒ…
                formatted_results = []
                for result in results:
                    formatted_result = {
                        "id": result.get("id", ""),
                        "score": result.get("score", 1.0),
                        "content": result.get("properties", {}).get("chunk", ""),
                        "properties": result.get("properties", {})
                    }
                    formatted_results.append(formatted_result)
                
                if sort_by_date:
                    formatted_results.sort(key=lambda x: self._parse_date_for_sorting(
                        x["properties"].get("s_created_date") or 
                        x["properties"].get("created_date")
                    ))
                
                
                return {
                    "success": True,
                    "class_name": class_name,
                    "filters": filters,
                    "total_results": len(formatted_results),
                    "results": formatted_results,
                    "search_timestamp": datetime.now().isoformat()
                }
            else:
                
                return {
                    "success": True,
                    "class_name": class_name,
                    "filters": filters,
                    "total_results": 0,
                    "results": [],
                    "message": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "search_timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"í•„í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "success": False,
                "error": f"í•„í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "results": []
            }
    
    async def extract_filter_from_query(self, query: str) -> Dict[str, Any]:
        """
        ì§ˆì˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œì™€ ë§¤í•‘ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ê²€ìƒ‰ ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì§ˆì˜ ë¬¸ìì—´
            
        Returns:
            {
                "filters": Dict[str, Any],  # ì¶”ì¶œëœ í•„í„° ì •ë³´ (Noneì´ë©´ ë§¤í•‘ë˜ì§€ ì•ŠìŒ)
                "search_type": str,  # "similarity" ë˜ëŠ” "filter"
                "reasoning": str     # íŒë‹¨ ê·¼ê±°
            }
        """
        try:
            logger.info(f"ğŸ” í•„í„° ì¶”ì¶œ ì‹œì‘: '{query}'")
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ í•„í„° ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_filter_extraction_prompt(query)
            
            # LLM í˜¸ì¶œ 
            extracted_filters = await self._extract_filters_with_llm(prompt)
            
            # ê²€ìƒ‰ ë°©ì‹ ê²°ì •
            search_type, reasoning = self._determine_search_type(query, extracted_filters)
            
            result = {
                "filters": extracted_filters.model_dump() if extracted_filters else None,
                "search_type": search_type,
                "reasoning": reasoning,
                "query": query,
            }
            
            logger.info(f"âœ… í•„í„° ì¶”ì¶œ ì™„ë£Œ: {search_type} ê²€ìƒ‰, í•„í„°: {extracted_filters}")
            return result
            
        except Exception as e:
            logger.error(f"í•„í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "filters": None,
                "search_type": "similarity",
                "reasoning": f"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {str(e)}",
                "query": query,
            }
    
    def _create_filter_extraction_prompt(self, query: str) -> str:
        """í•„í„° ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆì˜: {query}

ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œ:
{self._format_db_fields()}

ì¶”ì¶œ ê·œì¹™:
1. ì§ˆì˜ì—ì„œ ëª…í™•í•˜ê²Œ ì–¸ê¸‰ëœ ì •ë³´ë§Œ ì¶”ì¶œ
2. ë‚ ì§œëŠ” Weaviate í•„í„° ì—°ì‚°ìë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì¶œ:
   - "2024ë…„ 1ì›”" â†’ {{"gte": "2024-01-01T00:00:00Z", "lt": "2024-02-01T00:00:00Z"}}
   - "2024ë…„ 1ì›” 15ì¼" â†’ {{"gte": "2024-01-15T00:00:00Z", "lt": "2024-01-16T00:00:00Z"}}
   - "2024ë…„ ì´í›„" â†’ {{"gte": "2024-01-01T00:00:00Z"}}
   - "2024ë…„ ì´ì „" â†’ {{"lt": "2024-01-01T00:00:00Z"}}
   - "2024ë…„" â†’ {{"gte": "2024-01-01T00:00:00Z", "lt": "2025-01-01T00:00:00Z"}}
3. ì´ë©”ì¼ ì£¼ì†ŒëŠ” ì •í™•íˆ ì¶”ì¶œ
4. íŒŒì¼ëª…, í´ë”ëª…ì€ ì •í™•íˆ ì¶”ì¶œ
5. ë³´ê´€ì(custodian) ì •ë³´ê°€ ëª…ì‹œëœ ê²½ìš° ì •í™•íˆ ì¶”ì¶œ
6. ë§¤í•‘ë˜ì§€ ì•ŠëŠ” ì •ë³´ëŠ” nullë¡œ ì„¤ì •
7. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "custodian": null,
    "ori_file_name": null,
    "s_created_date": null,
    "sent_date": null,
    "from_email": null,
    "to_email": null,
    "cc": null,
    "bcc": null,
    "last_author": null,
    "extension": null
}}

ì˜ˆì‹œ:
- ì§ˆì˜: "2024ë…„ 1ì›”ì— ìƒì„±ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”" â†’ {{"s_created_date": {{"gte": "2024-01-01T00:00:00Z", "lt": "2024-02-01T00:00:00Z"}}, ...}}
- ì§ˆì˜: "2024ë…„ ì´í›„ ìƒì„±ëœ ë¬¸ì„œ" â†’ {{"s_created_date": {{"gte": "2024-01-01T00:00:00Z"}}, ...}}
- ì§ˆì˜: "2024ë…„ 1ì›” 15ì¼ì— ìƒì„±ëœ ë¬¸ì„œ" â†’ {{"s_created_date": {{"gte": "2024-01-15T00:00:00Z", "lt": "2024-01-16T00:00:00Z"}}, ...}}
- ì§ˆì˜: "user@example.comì´ ë³´ë‚¸ ì´ë©”ì¼" â†’ {{"from_email": "user@example.com", ...}}
- ì§ˆì˜: "í™©ì¬ì„­ì´ ë³´ë‚¸ ì´ë©”ì¼" â†’ {{"from_email": "í™©ì¬ì„­", ...}}
- ì§ˆì˜: "ì´ë¯¼ìš°ê°€ ë°›ì€ ì´ë©”ì¼" â†’ {{"to_email": "ì´ë¯¼ìš°", ...}}
- ì§ˆì˜: "ë³´ê´€ì: ê¹€ì² ìˆ˜, íŒŒì¼: report.pdf" â†’ {{"custodian": "ê¹€ì² ìˆ˜", "ori_file_name": "report.pdf", ...}}
"""
        return prompt
    
    def _format_db_fields(self) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        formatted = []
        for field, description in self.db_fields.items():
            formatted.append(f"- {field}: {description}")
        return "\n".join(formatted)
    
    async def _extract_filters_with_llm(self, prompt: str) -> FilterExtractionResult:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ í•„í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="/data/models_ckpt/Qwen3-32B",
                messages=[
                    {"role": "system", "content": "ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”: {prompt}"}
                ],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            content = response.choices[0].message.content

            # JSON íŒŒì‹±í•˜ì—¬ FilterExtractionResult ê°ì²´ ìƒì„±
            parsed_data = json.loads(content)
            result = FilterExtractionResult(**parsed_data)
            
            # USE_NAME_REVISIONì´ Trueì¸ ê²½ìš° ì´ë¦„ ê´€ë ¨ í•„ë“œì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ìˆ˜í–‰
            if USE_NAME_REVISION:
                result = await self._apply_name_revision(result, prompt)
            
            return result
            
        except Exception as e:
            logger.error(f"LLM í•„í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_empty_filters()
    
    async def _apply_name_revision(self, filters: FilterExtractionResult, original_prompt: str) -> FilterExtractionResult:
        """ì´ë¦„ ê´€ë ¨ í•„ë“œì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ì„ ì ìš©í•˜ì—¬ ë” ì •í™•í•œ ê°’ì„ ì°¾ìŠµë‹ˆë‹¤."""
        try:
            # ì´ë¦„ ê´€ë ¨ í•„ë“œë“¤
            name_fields = {
                "from_email": "from",
                "to_email": "to", 
                "custodian": "custodian",
                "last_author": "last_author"
            }
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ uniqueí•œ ê°’ë“¤ì„ í•œ ë²ˆë§Œ ê°€ì ¸ì˜´
            unique_names_result = await self.get_unique_names()
            if not unique_names_result["success"]:
                logger.warning("âš ï¸ Unique ì´ë¦„ ì¡°íšŒ ì‹¤íŒ¨ë¡œ ì´ë¦„ ìˆ˜ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return filters
            
            for field_name, field_type in name_fields.items():
                current_value = getattr(filters, field_name)
                if current_value and isinstance(current_value, str) and current_value.strip():
                    # ë¨¼ì € ì •í™•í•œ ë§¤ì¹­ì´ ìˆëŠ”ì§€ í™•ì¸ (ì´ë¯¸ ê°€ì ¸ì˜¨ ë°ì´í„° ì‚¬ìš©)
                    exact_match = self._check_exact_match_with_data(current_value, field_type, unique_names_result)
                    if exact_match:
                        logger.info(f"âœ… {field_name} í•„ë“œ ì •í™•í•œ ë§¤ì¹­ ë°œê²¬: '{current_value}'")
                        continue
                    
                    # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ì„ ë•Œë§Œ ìœ ì‚¬ë„ ë§¤ì¹­ ìˆ˜í–‰ (ì´ë¯¸ ê°€ì ¸ì˜¨ ë°ì´í„° ì‚¬ìš©)
                    similar_result = await self._find_name_matches_with_existing_data(
                        query_input=current_value,
                        field_type=field_type,
                        unique_names_result=unique_names_result,
                        limit=3
                    )
                    
                    if similar_result["success"] and similar_result["matches"]:
                        # ê°€ì¥ ìœ ì‚¬í•œ ë§¤ì¹˜ë¥¼ ì„ íƒ
                        best_match = similar_result["matches"][0]
                        if best_match["similarity_score"] > 0.7:  # ìœ ì‚¬ë„ ì„ê³„ê°’
                            setattr(filters, field_name, best_match["name"])
                            logger.info(f"âœ… {field_name} í•„ë“œ ìˆ˜ì •: '{current_value}' â†’ '{best_match['name']}' (ìœ ì‚¬ë„: {best_match['similarity_score']:.2f})")
                        else:
                            logger.info(f"âš ï¸ {field_name} í•„ë“œ ìœ ì‚¬ë„ ë¶€ì¡±: '{current_value}' (ìµœê³  ìœ ì‚¬ë„: {best_match['similarity_score']:.2f})")
                    else:
                        logger.info(f"â„¹ï¸ {field_name} í•„ë“œì— ëŒ€í•œ ìœ ì‚¬í•œ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: '{current_value}'")
            
            return filters
            
        except Exception as e:
            logger.error(f"ì´ë¦„ ìˆ˜ì • ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            return filters
    
    async def _check_exact_match(self, value: str, field_type: str) -> bool:
        """ì •í™•í•œ ë§¤ì¹­ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ uniqueí•œ ê°’ë“¤ì„ ê°€ì ¸ì˜´
            unique_names_result = await self.get_unique_names()
            if not unique_names_result["success"]:
                return False
            
            # í•„ë“œ íƒ€ì…ì— ë”°ë¼ ê²€ìƒ‰ ëŒ€ìƒ ê²°ì •
            search_names = []
            if field_type == "from":
                search_names = unique_names_result["names"]["from_emails"]
            elif field_type == "to":
                search_names = unique_names_result["names"]["to_emails"]
            elif field_type == "custodian":
                search_names = unique_names_result["names"]["custodian"]
            elif field_type == "last_author":
                search_names = unique_names_result["names"]["last_author"]
            
            # ì •í™•í•œ ë§¤ì¹­ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            return value.lower().strip() in [name.lower().strip() for name in search_names]
            
        except Exception as e:
            logger.error(f"ì •í™•í•œ ë§¤ì¹­ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _check_exact_match_with_data(self, value: str, field_type: str, unique_names_result: Dict[str, Any]) -> bool:
        """ì´ë¯¸ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            # í•„ë“œ íƒ€ì…ì— ë”°ë¼ ê²€ìƒ‰ ëŒ€ìƒ ê²°ì •
            search_names = []
            if field_type == "from":
                search_names = unique_names_result["names"]["from_emails"]
            elif field_type == "to":
                search_names = unique_names_result["names"]["to_emails"]
            elif field_type == "custodian":
                search_names = unique_names_result["names"]["custodian"]
            elif field_type == "last_author":
                search_names = unique_names_result["names"]["last_author"]
            
            # ì •í™•í•œ ë§¤ì¹­ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            return value.lower().strip() in [name.lower().strip() for name in search_names]
            
        except Exception as e:
            logger.error(f"ì •í™•í•œ ë§¤ì¹­ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    async def _find_name_matches_with_existing_data(self, query_input: str, field_type: str, 
                                                   unique_names_result: Dict[str, Any], limit: int) -> Dict[str, Any]:
        """ì´ë¯¸ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¦„ ìœ ì‚¬ë„ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # ì´ë©”ì¼ íƒ€ì…ì— ë”°ë¼ ê²€ìƒ‰ ëŒ€ìƒ ê²°ì •
            search_names = []
            if field_type == "from" or field_type == "all":
                search_names.extend(unique_names_result["names"]["from_emails"])
            if field_type == "to" or field_type == "all":
                search_names.extend(unique_names_result["names"]["to_emails"])
            if field_type == "custodian" or field_type == "all":
                search_names.extend(unique_names_result["names"]["custodian"])
            if field_type == "last_author" or field_type == "all":
                search_names.extend(unique_names_result["names"]["last_author"])
            
            # ì¤‘ë³µ ì œê±°
            search_names = list(set(search_names))
            
            if not search_names:
                return {
                    "success": True,
                    "query_input": query_input,
                    "field_type": field_type,
                    "message": "ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë©”ì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "matches": [],
                    "timestamp": datetime.now().isoformat()
                }
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ë„ ë§¤ì¹­ ìˆ˜í–‰
            matches = await self._find_name_matches_with_llm(query_input, search_names, limit)
            
            result = {
                "success": True,
                "query_input": query_input,
                "email_type": field_type,
                "total_candidates": len(search_names),
                "matches": matches,
                "timestamp": datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"ì´ë¦„ ìœ ì‚¬ë„ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "success": False,
                "error": f"ì´ë¦„ ìœ ì‚¬ë„ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "matches": []
            }
    
    def _get_empty_filters(self) -> FilterExtractionResult:
        """ë¹ˆ í•„í„° Pydantic ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return FilterExtractionResult(
            custodian=None,
            ori_file_name=None,
            s_created_date=None,
            sent_date=None,
            from_email=None,
            to_email=None,
            cc=None,
            bcc=None,
            last_author=None,
            extension=None
        )
        
        
    
    def _determine_search_type(self, query: str, filters: FilterExtractionResult) -> tuple[str, str]:
        """ê²€ìƒ‰ ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤."""
        try:
            # ì¿¼ë¦¬ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ ë‚˜íƒ€ë‚´ëŠ” í‚¤ì›Œë“œ í™•ì¸
            similarity_keywords = [
                "~ì— ê´€í•œ", "~ì— ëŒ€í•œ", "~ì™€ ìœ ì‚¬í•œ", "ë¹„ìŠ·í•œ", "ê°™ì€", "ìœ ì‚¬í•œ", 
                "ê´€ë ¨ëœ", "ì—°ê´€ëœ", "ì°¸ê³ í• ", "ì°¸ê³ ìš©", "ì°¸ê³  ìë£Œ", "ì°¸ê³  ë¬¸ì„œ",
                "~ì™€ ê°™ì€", "~ì™€ ë¹„ìŠ·í•œ", "~ì™€ ê´€ë ¨ëœ", "~ì™€ ì—°ê´€ëœ"
            ]
            
            # ì¿¼ë¦¬ì— ìœ ì‚¬ì„± í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_similarity_keyword = any(keyword in query for keyword in similarity_keywords)
            
            # í•„í„°ê°€ ëª¨ë‘ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
            if not filters or all(v is None for v in filters.model_dump().values()):
                if has_similarity_keyword:
                    return "similarity", "ì§ˆì˜ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë°œê²¬í•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
                return "similarity", "ì§ˆì˜ì—ì„œ êµ¬ì²´ì ì¸ í•„í„° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            # ìœ íš¨í•œ í•„í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            valid_filters = {k: v for k, v in filters.model_dump().items() if v is not None}
            
            if not valid_filters:
                if has_similarity_keyword:
                    return "similarity", "ì§ˆì˜ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë°œê²¬í•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
                return "similarity", "ì§ˆì˜ì—ì„œ ìœ íš¨í•œ í•„í„° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            # ìœ ì‚¬ì„± í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ similarity ê²€ìƒ‰ ìš°ì„ 
            if has_similarity_keyword:
                return "similarity", "ì§ˆì˜ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë°œê²¬í•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            # íŠ¹ì • ì¡°ê±´ë“¤ì´ ëª¨ë‘ ë§Œì¡±ë˜ëŠ” ê²½ìš° í•„í„° ê²€ìƒ‰ ì‚¬ìš©
            if len(valid_filters) >= 2:
                return "filter", f"ì§ˆì˜ì—ì„œ {len(valid_filters)}ê°œì˜ êµ¬ì²´ì ì¸ í•„í„° ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {list(valid_filters.keys())}. ì¡°ê±´ í•„í„°ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            # ë‹¨ì¼ í•„í„°ì¸ ê²½ìš° ì§ˆì˜ì˜ ë³µì¡ì„±ì— ë”°ë¼ ê²°ì •
            if len(valid_filters) == 1:
                field, value = list(valid_filters.items())[0]
                
                # ì´ë©”ì¼ì´ë‚˜ íŒŒì¼ëª… ë“± êµ¬ì²´ì ì¸ ì‹ë³„ìê°€ ìˆëŠ” ê²½ìš°
                if field in ["from_email", "to_email", "ori_file_name"]:
                    return "filter", f"ì§ˆì˜ì—ì„œ êµ¬ì²´ì ì¸ ì‹ë³„ì '{field}: {value}'ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì¡°ê±´ í•„í„°ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
                
                # ë‚ ì§œ í•„ë“œì¸ ê²½ìš°
                elif field in ["s_created_date", "sent_date"]:
                    return "filter", f"ì§ˆì˜ì—ì„œ êµ¬ì²´ì ì¸ ë‚ ì§œ ì •ë³´ '{field}: {value}'ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì¡°ê±´ í•„í„°ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
                
                # ê¸°íƒ€ í•„ë“œì¸ ê²½ìš°
                else:
                    return "similarity", f"ì§ˆì˜ì—ì„œ êµ¬ì²´ì ì¸ í•„í„° ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ ë‹¨ì¼ í•„í„°ì´ë¯€ë¡œ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            return "similarity", "ê¸°ë³¸ì ìœ¼ë¡œ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ë°©ì‹ ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return "similarity", f"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {str(e)}"
    
    def _parse_date_for_sorting(self, date_input) -> str:
        """ì •ë ¬ì„ ìœ„í•œ ë‚ ì§œ ì…ë ¥ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""

        # datetime ê°ì²´ì¸ ê²½ìš°
        if isinstance(date_input, datetime):
            return date_input.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        # ë¬¸ìì—´ì¸ ê²½ìš°
        if isinstance(date_input, str):
            # RFC3339 í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            if not date_input.endswith('Z') and 'T' in date_input:
                try:
                    # ISO í˜•ì‹ì„ RFC3339ë¡œ ë³€í™˜
                    dt = datetime.fromisoformat(date_input.replace('Z', '+00:00'))
                    return dt.strftime("%Y-%m-%dT%H:%M:%SZ")
                except:
                    pass
            
            return date_input
        
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.rag_db:
                self.rag_db.close()
                self.rag_db = None
            
            self.initialized = False
            logger.info("Weaviate MCP ë„êµ¬ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def get_tool_descriptions(self) -> List[Dict[str, str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì˜ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        tools = [
            {
                "name": "search_documents",
                "description": "ì¿¼ë¦¬ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. í•„í„°ê°€ ì œê³µë˜ë©´ ë©”íƒ€ë°ì´í„° í•„í„°ì™€ í•¨ê»˜ ê²€ìƒ‰í•˜ê³ , í•„í„°ê°€ ì—†ìœ¼ë©´ ë‹¨ìˆœ RAG ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                "parameters": {
                    "query": "ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´ (í•„ìˆ˜)",
                    "filters": "ë©”íƒ€ë°ì´í„° í•„í„° ë”•ì…”ë„ˆë¦¬ (ì„ íƒì‚¬í•­, Noneì´ë©´ ë‹¨ìˆœ RAG ê²€ìƒ‰)",
                    "sort_by_date": "ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: false)",
                    "limit": "ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)",
                    "db_name": "ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)"
                }
            },
            {
                "name": "get_document_with_filter",
                "description": "íŠ¹ì • í´ë˜ìŠ¤ì—ì„œ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì¿¼ë¦¬ ì—†ì´ í•„í„°ë§Œìœ¼ë¡œ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
                "parameters": {
                    "class_name": "ê²€ìƒ‰í•  í´ë˜ìŠ¤ ì´ë¦„ (í•„ìˆ˜)",
                    "limit": "ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (í•„ìˆ˜)",
                    "filters": "ë©”íƒ€ë°ì´í„° í•„í„° ë”•ì…”ë„ˆë¦¬ (ì„ íƒì‚¬í•­, Noneì´ë©´ ëª¨ë“  ë¬¸ì„œ ë°˜í™˜)",
                    "db_name": "ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)"
                }
            },
            {
                "name": "extract_filter_from_query",
                "description": "ì§ˆì˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œì™€ ë§¤í•‘ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ê²€ìƒ‰ ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.",
                "parameters": {
                    "query": "ì‚¬ìš©ì ì§ˆì˜ ë¬¸ìì—´ (í•„ìˆ˜)"
                }
            },
            {
                "name": "get_unique_names",
                "description": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì´ë¦„ì´ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” í•„ë“œì˜ ëª¨ë“  uniqueí•œ ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.",
                "parameters": {
                    "db_name": "ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)"
                }
            },
            {
                "name": "find_similar_name",
                "description": "ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œí•œ ì´ë©”ì¼ ê°’ ë˜ëŠ” ì´ë¦„ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì´ë©”ì¼ì„ ì°¾ìŠµë‹ˆë‹¤. LLMì´ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë§¤ì¹˜ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤. í•œê¸€/ì˜ì–´ ì´ë¦„, ì´ë©”ì¼ ì£¼ì†Œ, ë¶€ë¶„ ì •ë³´ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì…ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.",
                "parameters": {
                    "query_input": "ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œí•œ ì´ë©”ì¼ ê°’ ë˜ëŠ” ì´ë¦„ (ì˜ˆ: 'ì¡°íš¨ì›', 'hyyoka@gmail.com', 'hyyoka') (í•„ìˆ˜)",
                    "field_type": "from, to, all ì¤‘ ì„ íƒ (ê¸°ë³¸ê°’: all)",
                    "db_name": "ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)",
                    "limit": "ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)"
                }
            }
        ]
        
        return tools

    async def get_unique_names(self, db_name: str = None) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì´ë¦„ì´ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” í•„ë“œì˜ ëª¨ë“  uniqueí•œ ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            db_name: ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)
            
        Returns:
            uniqueí•œ ì´ë©”ì¼ ê°’ë“¤ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹¤ë¥¸ DBë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš° ì¬ì´ˆê¸°í™”
            if not self.initialized or (db_name and db_name != self.default_db_name):
                if not await self.initialize_rag_db(db_name):
                    return {
                        "success": False,
                        "error": "ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                        "names": {"from_emails": [], "to_emails": [],  "custodian": [], "last_author": []}
                    }
            
            if not self.rag_db:
                return {
                    "success": False,
                    "error": "RAG ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                     "names": {"from_emails": [], "to_emails": [],  "custodian": [], "last_author": []}
                }
                
      
            logger.info("ğŸ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ uniqueí•œ ì´ë©”ì¼ ê°’ë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤.")
            
            # from_emailê³¼ to_emailì˜ uniqueí•œ ê°’ë“¤ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ì¿¼ë¦¬
            from_emails = await self.rag_db.get_unique_values("from_email")
            to_emails = await self.rag_db.get_unique_values("to_email")
            custodian = await self.rag_db.get_unique_values("custodian")
            last_author = await self.rag_db.get_unique_values("last_author")
            
            
            
            # ê²°ê³¼ ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°
            unique_from_emails = list(set([email for email in from_emails if email]))
            unique_to_emails = list(set([email for email in to_emails if email]))
            unique_custodian = list(set([name for name in custodian if name]))
            unique_last_author = list(set([name for name in last_author if name]))
            
            # ì •ë ¬
            unique_from_emails.sort()
            unique_to_emails.sort()
            unique_custodian.sort()
            unique_last_author.sort()
            
            result = {
                "success": True,
                "total_from_emails": len(unique_from_emails),
                "total_to_emails": len(unique_to_emails),
                "total_custodian": len(unique_custodian),
                "total_last_author": len(unique_last_author),
                "names": {
                    "from_emails": unique_from_emails,
                    "to_emails": unique_to_emails,
                    "custodian": unique_custodian,
                    "last_author": unique_last_author
                },
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… Unique ì´ë¦„ë“¤ ì¡°íšŒ ì™„ë£Œ: from_email {len(unique_from_emails)}ê°œ, to_email {len(unique_to_emails)}ê°œ, custodian {len(unique_custodian)}, total_last_author:  {len(unique_last_author)}")
            return result
            
        except Exception as e:
            logger.error(f"Unique ì´ë¦„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "success": False,
                "error": f"Unique ì´ë¦„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "names": {"from_emails": [], "to_emails": [],  "custodian": [], "last_author": []}
            }
    
    async def find_similar_name(self, query_input: str, field_type: str = "all", 
                                db_name: str = None, limit: int = 5) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œí•œ ì´ë©”ì¼ ê°’ ë˜ëŠ” ì´ë¦„ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì´ë©”ì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        LLMì´ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë§¤ì¹˜ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
        
        Args:
            query_input: ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œí•œ ì´ë©”ì¼ ê°’ ë˜ëŠ” ì´ë¦„ (ì˜ˆ: "ì¡°íš¨ì›", "hyyoka@gmail.com", "hyyoka")
            email_type: "from", "to", "both" ì¤‘ ì„ íƒ (ê¸°ë³¸ê°’: "all")
            db_name: ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)
            
        Returns:
            ìœ ì‚¬í•œ ì´ë©”ì¼ ë§¤ì¹˜ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not query_input:
                return {
                    "success": False,
                    "error": "ì¿¼ë¦¬ ì…ë ¥ ê°’ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "matches": []
                }
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ uniqueí•œ ì´ë©”ì¼ ê°’ë“¤ì„ ê°€ì ¸ì˜´
            unique_emails_result = await self.get_unique_names(db_name)
            if not unique_emails_result["success"]:
                return unique_emails_result
            
            # ì´ë©”ì¼ íƒ€ì…ì— ë”°ë¼ ê²€ìƒ‰ ëŒ€ìƒ ê²°ì •
            search_names = []
            if field_type == "from" or field_type == "all":
                search_names.extend(unique_emails_result["names"]["from_emails"])
            if field_type == "to" or field_type == "all":
                search_names.extend(unique_emails_result["names"]["to_emails"])
            if field_type == "custodian" or field_type == "all":
                search_names.extend(unique_emails_result["names"]["custodian"])
            if field_type == "last_author" or field_type == "all":
                search_names.extend(unique_emails_result["names"]["last_author"])
            
            # ì¤‘ë³µ ì œê±°
            search_names = list(set(search_names))
            
            if not search_names:
                return {
                    "success": True,
                    "query_input": query_input,
                    "field_type": field_type,
                    "message": "ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë©”ì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "matches": [],
                    "timestamp": datetime.now().isoformat()
                }
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ë„ ë§¤ì¹­ ìˆ˜í–‰
            matches = await self._find_name_matches_with_llm(query_input, search_names, limit)
            
            result = {
                "success": True,
                "query_input": query_input,
                "email_type": field_type,
                "total_candidates": len(search_names),
                "matches": matches,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ì´ë©”ì¼ ìœ ì‚¬ë„ ë§¤ì¹­ ì™„ë£Œ: '{query_input}' â†’ {len(matches)}ê°œ ë§¤ì¹˜")
            return result
            
        except Exception as e:
            logger.error(f"ì´ë©”ì¼ ìœ ì‚¬ë„ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "success": False,
                "error": f"ì´ë©”ì¼ ìœ ì‚¬ë„ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "matches": []
            }
    
    async def _find_name_matches_with_llm(self, query_input: str, candidate_names: List[str], 
                                          limit: int) -> List[Dict[str, Any]]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¦„ ìœ ì‚¬ë„ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # LLMì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_name_matching_prompt(query_input, candidate_names, limit)
            
            # LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="/data/models_ckpt/Qwen3-32B",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì´ë©”ì¼ ì£¼ì†Œì™€ ì´ë¦„ì˜ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ í›„ë³´ë“¤ì„ ì„ íƒí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            content = response.choices[0].message.content
            parsed_data = json.loads(content)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            matches = []
            for match in parsed_data.get("matches", []):
                matches.append({
                    "name": match.get("name", ""),
                    "similarity_score": match.get("similarity_score", 0.0),
                    "reasoning": match.get("reasoning", ""),
                    "match_type": match.get("match_type", "unknown")
                })
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            matches.sort(key=lambda x: x["similarity_score"], reverse=True)
            
            return matches[:limit]
            
        except Exception as e:
            logger.error(f"LLM ì´ë©”ì¼ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜: {e}")
            # LLM ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ìœ¼ë¡œ í´ë°±
            return self._fallback_name_matching(query_input, candidate_names, limit)
    
    def _create_name_matching_prompt(self, query_input: str, candidate_names: List[str], 
                                     limit: int) -> str:
        """ì´ë©”ì¼ ë§¤ì¹­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = f"""
ë‹¹ì‹ ì€ ì´ë©”ì¼ ì£¼ì†Œì™€ ì´ë¦„ì˜ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì¿¼ë¦¬ ì…ë ¥: {query_input}

í›„ë³´ ì´ë©”ì¼ ëª©ë¡:
{chr(10).join([f"{i+1}. {name}" for i, name in enumerate(candidate_names)])}

ë§¤ì¹­ ê·œì¹™:
1. ì •í™•í•œ ì¼ì¹˜ (100ì ): 
   - ì´ë©”ì¼ ì£¼ì†Œê°€ ì™„ì „íˆ ì¼ì¹˜
   - ì´ë¦„ì´ ì™„ì „íˆ ì¼ì¹˜ (ì˜ˆ: "ì¡°íš¨ì›" â†” "ì¡°íš¨ì›")
2. ì´ë¦„ ìœ ì‚¬ (90ì ): 
   - ì´ë¦„ì˜ ìˆœì„œê°€ ë°”ë€ ê²½ìš° (ì˜ˆ: "ì¡°íš¨ì›" â†” "íš¨ì› ì¡°")
   - ì˜ì–´ ì´ë¦„ê³¼ í•œê¸€ ì´ë¦„ ë§¤ì¹­ (ì˜ˆ: "hyowon cho" â†” "ì¡°íš¨ì›")
   - ì•½ì–´ë‚˜ ë³„ì¹­ í¬í•¨ (ì˜ˆ: "hyowon cho (KC)" â†” "ì¡°íš¨ì›")
   - ë§Œì•½ ì´ë¦„ì´ ì•„ì˜ˆ ë‹¤ë¥´ë‹¤ë©´, ëŒ€ìƒì´ ì•„ë‹˜ (ì˜ˆ: Cho, SelenaëŠ” ì¡°íš¨ì›ê³¼ ë§¤ì¹­ë  ìˆ˜ ì—†ìŒ)
3. ì´ë©”ì¼ ì‚¬ìš©ìëª… ì¼ì¹˜ (80ì ): 
   - ì´ë©”ì¼ì˜ @ ì• ë¶€ë¶„ì´ ì¼ì¹˜ (ì˜ˆ: "hyyoka" â†” "hyyoka@gmail.com")
4. ë¶€ë¶„ ì¼ì¹˜ (30ì ): 
   - ì´ë¦„ì˜ ì¼ë¶€ê°€ ì¼ì¹˜í•˜ê±°ë‚˜ ìœ ì‚¬
   - ì´ë©”ì¼ ì£¼ì†Œì˜ ì¼ë¶€ê°€ ì¼ì¹˜
6. ê´€ë ¨ì„± (5ì ): 
   - ì—…ë¬´ì , ì¡°ì§ì  ê´€ë ¨ì„±ì´ ìˆëŠ” ê²½ìš°

íŠ¹ë³„ ê³ ë ¤ì‚¬í•­:
- "hyowon cho (KC)"ì™€ "ì¡°íš¨ì›"ì€ ê°™ì€ ì‚¬ëŒìœ¼ë¡œ ê°„ì£¼
- "hyyoka@gmail.com"ì—ì„œ "hyyoka"ë§Œ ì…ë ¥ëœ ê²½ìš°ë„ ë§¤ì¹­
- í•œê¸€ ì´ë¦„ê³¼ ì˜ì–´ ì´ë¦„ì˜ ë§¤ì¹­ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤
- ê´„í˜¸ ì•ˆì˜ ì•½ì–´ë‚˜ ë³„ì¹­ë„ ê³ ë ¤

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "matches": [
        {{
            "name": "ì´ë©”ì¼ì£¼ì†Œ í˜¹ì€ ì´ë¦„",
            "similarity_score": 0.0-100.0,
            "reasoning": "ë§¤ì¹­ ì´ìœ  ì„¤ëª…",
            "match_type": "exact|name_similar|username|domain|partial|related"
        }}
    ]
}}

ê°€ì¥ ìœ ì‚¬í•œ {limit}ê°œì˜ ì´ë©”ì¼ì„ ì„ íƒí•˜ê³ , ê°ê°ì— ëŒ€í•´ ìœ ì‚¬ë„ ì ìˆ˜ì™€ ë§¤ì¹­ ì´ìœ ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""
        return prompt
    
    def _fallback_name_matching(self, query_input: str, candidate_names: List[str], 
                                limit: int) -> List[Dict[str, Any]]:
        """LLM ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤."""
        try:
            matches = []
            
            for name in candidate_names:
                if not name:
                    continue
                
                # ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚°
                similarity_score = self._calculate_simple_similarity(query_input, name)
                
                if similarity_score > 0:
                    match_type = self._determine_match_type(query_input, name)
                    reasoning = f"ë¬¸ìì—´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­: {similarity_score:.1f}%"
                    
                    matches.append({
                        "name": name,
                        "similarity_score": similarity_score,
                        "reasoning": reasoning,
                        "match_type": match_type
                    })
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            matches.sort(key=lambda x: x["similarity_score"], reverse=True)
            
            return matches[:limit]
            
        except Exception as e:
            logger.error(f"í´ë°± ì´ë©”ì¼ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _calculate_simple_similarity(self, query_input: str, candidate_name: str) -> float:
        """ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            if not query_input or not candidate_name:
                return 0.0
            
            query_lower = query_input.lower()
            candidate_lower = candidate_name.lower()
            
            # ì •í™•í•œ ì¼ì¹˜
            if query_lower == candidate_lower:
                return 100.0
            
            # ì´ë©”ì¼ ì£¼ì†Œì¸ì§€ í™•ì¸
            if '@' in query_lower and '@' in candidate_lower:
                # ë„ë©”ì¸ê³¼ ì‚¬ìš©ìëª… ë¶„ë¦¬
                query_parts = query_lower.split('@')
                candidate_parts = candidate_lower.split('@')
                
                if len(query_parts) == 2 and len(candidate_parts) == 2:
                    query_user, query_domain = query_parts
                    candidate_user, candidate_domain = candidate_parts
                    
                    # ë„ë©”ì¸ ì¼ì¹˜ (80ì )
                    if query_domain == candidate_domain:
                        # ì‚¬ìš©ìëª… ìœ ì‚¬ë„ ê³„ì‚°
                        user_similarity = self._calculate_string_similarity(query_user, candidate_user)
                        return 80.0 + (user_similarity * 20.0)
                    
                    # ì‚¬ìš©ìëª… ì¼ì¹˜ (60ì )
                    if query_user == candidate_user:
                        # ë„ë©”ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                        domain_similarity = self._calculate_string_similarity(query_domain, candidate_domain)
                        return 60.0 + (domain_similarity * 20.0)
                    
                    # ë¶€ë¶„ ì¼ì¹˜ (ìµœëŒ€ 40ì )
                    user_similarity = self._calculate_string_similarity(query_user, candidate_user)
                    domain_similarity = self._calculate_string_similarity(query_domain, candidate_domain)
                    
                    return max(user_similarity, domain_similarity) * 40.0
            
            # ì´ë¦„ ê¸°ë°˜ ë§¤ì¹­ (ì´ë©”ì¼ì´ ì•„ë‹Œ ê²½ìš°)
            # ê´„í˜¸ì™€ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            query_clean = self._clean_name_string(query_lower)
            candidate_clean = self._clean_name_string(candidate_lower)
            
            # ì •í™•í•œ ì´ë¦„ ì¼ì¹˜ (90ì )
            if query_clean == candidate_clean:
                return 90.0
            
            # ì´ë¦„ ìœ ì‚¬ë„ ê³„ì‚° (ìµœëŒ€ 70ì )
            name_similarity = self._calculate_name_similarity(query_clean, candidate_clean)
            return name_similarity * 70.0
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _calculate_string_similarity(self, str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (Jaccard ìœ ì‚¬ë„ ê¸°ë°˜)."""
        try:
            if not str1 or not str2:
                return 0.0
            
            # ë¬¸ì ë‹¨ìœ„ë¡œ ì§‘í•© ìƒì„±
            set1 = set(str1)
            set2 = set(str2)
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(set1.intersection(set2))
            union = len(set1.union(set2))
            
            if union == 0:
                return 0.0
            
            return (intersection / union) * 100.0
            
        except Exception as e:
            logger.error(f"ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _determine_match_type(self, query_input: str, candidate_name: str) -> str:
        """ë§¤ì¹­ íƒ€ì…ì„ ê²°ì •í•©ë‹ˆë‹¤."""
        try:
            if not query_input or not candidate_name:
                return "unknown"
            
            query_lower = query_input.lower()
            candidate_lower = candidate_name.lower()
            
            if query_lower == candidate_lower:
                return "exact"
            
            # ì´ë©”ì¼ ì£¼ì†Œì¸ì§€ í™•ì¸
            if '@' in query_lower and '@' in candidate_lower:
                query_parts = query_lower.split('@')
                candidate_parts = candidate_lower.split('@')
                
                if len(query_parts) == 2 and len(candidate_parts) == 2:
                    query_user, query_domain = query_parts
                    candidate_user, candidate_domain = candidate_parts
                    
                    if query_domain == candidate_domain:
                        return "domain"
                    elif query_user == candidate_user:
                        return "username"
                    else:
                        return "partial"
            
            # ì´ë¦„ ê¸°ë°˜ ë§¤ì¹­
            query_clean = self._clean_name_string(query_lower)
            candidate_clean = self._clean_name_string(candidate_lower)
            
            if query_clean == candidate_clean:
                return "name_similar"
            else:
                return "partial"
                
        except Exception as e:
            logger.error(f"ë§¤ì¹­ íƒ€ì… ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return "unknown"
    
    def _clean_name_string(self, name: str) -> str:
        """ì´ë¦„ ë¬¸ìì—´ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        try:
            if not name:
                return ""
            
            # ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš© ì œê±°
            import re
            name = re.sub(r'\([^)]*\)', '', name)
            
            # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ê³µë°±, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ëŠ” ìœ ì§€)
            name = re.sub(r'[^\w\s\-_]', '', name)
            
            # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
            name = re.sub(r'\s+', ' ', name)
            
            # ì•ë’¤ ê³µë°± ì œê±°
            name = name.strip()
            
            return name
            
        except Exception as e:
            logger.error(f"ì´ë¦„ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return name
    
    def _calculate_name_similarity(self, name1: str, name2: str) -> float:
        """ë‘ ì´ë¦„ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            if not name1 or not name2:
                return 0.0
            
            # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¹„êµ
            words1 = set(name1.split())
            words2 = set(name2.split())
            
            if not words1 or not words2:
                return 0.0
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            
            if union == 0:
                return 0.0
            
            base_similarity = intersection / union
            
            # ì¶”ê°€ì ì¸ ì´ë¦„ ë§¤ì¹­ ë¡œì§
            # 1. í•œê¸€ ì´ë¦„ê³¼ ì˜ì–´ ì´ë¦„ ë§¤ì¹­
            korean_match = self._check_korean_english_match(name1, name2)
            if korean_match:
                base_similarity = max(base_similarity, 0.8)
            
            # 2. ì´ë¦„ ìˆœì„œ ë°”ë€ ê²½ìš°
            if self._check_name_order_reversed(name1, name2):
                base_similarity = max(base_similarity, 0.7)
            
            # 3. ë¶€ë¶„ ì´ë¦„ ë§¤ì¹­
            partial_match = self._check_partial_name_match(name1, name2)
            if partial_match:
                base_similarity = max(base_similarity, 0.6)
            
            return base_similarity * 100.0
            
        except Exception as e:
            logger.error(f"ì´ë¦„ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.0
    
    def _check_korean_english_match(self, name1: str, name2: str) -> bool:
        """í•œê¸€ ì´ë¦„ê³¼ ì˜ì–´ ì´ë¦„ì˜ ë§¤ì¹­ì„ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            # ê°„ë‹¨í•œ í•œê¸€/ì˜ì–´ êµ¬ë¶„ (ìœ ë‹ˆì½”ë“œ ë²”ìœ„ ì‚¬ìš©)
            def is_korean(text):
                return any('\uac00' <= char <= '\ud7af' for char in text)
            
            def is_english(text):
                return all(char.isascii() and char.isalpha() or char.isspace() for char in text)
            
            # í•œìª½ì€ í•œê¸€, ë‹¤ë¥¸ ìª½ì€ ì˜ì–´ì¸ ê²½ìš°
            if (is_korean(name1) and is_english(name2)) or (is_english(name1) and is_korean(name2)):
                # ê³µí†µ ë‹¨ì–´ë‚˜ ë¶€ë¶„ ë§¤ì¹­ í™•ì¸
                words1 = set(name1.lower().split())
                words2 = set(name2.lower().split())
                
                # ê³µí†µ ë‹¨ì–´ê°€ ìˆê±°ë‚˜ ë¶€ë¶„ ë§¤ì¹­ì´ ìˆëŠ” ê²½ìš°
                if words1.intersection(words2):
                    return True
                
                # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ í™•ì¸
                for word1 in words1:
                    for word2 in words2:
                        if word1 in word2 or word2 in word1:
                            return True
                
                return False
            
            return False
            
        except Exception as e:
            logger.error(f"í•œê¸€-ì˜ì–´ ë§¤ì¹­ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _check_name_order_reversed(self, name1: str, name2: str) -> bool:
        """ì´ë¦„ì˜ ìˆœì„œê°€ ë°”ë€ ê²½ìš°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            words1 = name1.split()
            words2 = name2.split()
            
            if len(words1) != len(words2) or len(words1) < 2:
                return False
            
            # ìˆœì„œê°€ ë°”ë€ ê²½ìš° í™•ì¸
            if words1 == words2[::-1]:
                return True
            
            # ë¶€ë¶„ì ìœ¼ë¡œ ìˆœì„œê°€ ë°”ë€ ê²½ìš°
            if len(words1) >= 2 and len(words2) >= 2:
                # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ë°”ë€ ê²½ìš°
                if words1[0] == words2[-1] and words1[-1] == words2[0]:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"ì´ë¦„ ìˆœì„œ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _check_partial_name_match(self, name1: str, name2: str) -> bool:
        """ë¶€ë¶„ì ì¸ ì´ë¦„ ë§¤ì¹­ì„ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            words1 = set(name1.split())
            words2 = set(name2.split())
            
            # ê³µí†µ ë‹¨ì–´ê°€ ìˆëŠ” ê²½ìš°
            if words1.intersection(words2):
                return True
            
            # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ í™•ì¸
            for word1 in words1:
                for word2 in words2:
                    if len(word1) >= 2 and len(word2) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                        if word1 in word2 or word2 in word1:
                            return True
            
            return False
            
        except Exception as e:
            logger.error(f"ë¶€ë¶„ ì´ë¦„ ë§¤ì¹­ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
