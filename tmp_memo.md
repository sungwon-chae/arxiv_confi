`torch_dtype` is deprecated! Use `dtype` instead!
=== ETU H200 GPU ìµœì í™” ì‹¤í–‰ ===
ğŸš€ H200 GPU í™˜ê²½ ì„¤ì • ì¤‘...
GPU 0: NVIDIA H200 (139.8 GB)
âœ… H200 GPU 1ê°œ ê°ì§€ë¨
[batch heuristic] optimal=128, mem_clamp=7, final=7
ğŸ”§ ì‚¬ìš©ì ì§€ì • ë°°ì¹˜ í¬ê¸° ì‚¬ìš©: 2 (heuristic=7)
ğŸ¯ ë‹¨ì¼ GPU ëª¨ë“œ: GPU 0
ğŸ”§ H200 ìµœì í™” ì„¤ì • ì ìš©:
   - strategy: single
   - batch_size: 2
   - batch_size_per_gpu: 8
   - frozen_on_cpu: False
   - lora_r: 16
   - lora_alpha: 512
   - max_num_batches: 5
   - mixed_precision: bf16
   - gradient_accumulation_steps: 4
ğŸš€ ETU ì‹¤í–‰ ì‹œì‘...
ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...

Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]
Loading checkpoint shards:  12%|â–ˆâ–        | 1/8 [00:00<00:06,  1.11it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:05,  1.10it/s]
Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:04,  1.09it/s]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:03<00:03,  1.10it/s]
Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:04<00:02,  1.10it/s]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:05<00:01,  1.11it/s]
Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:06<00:00,  1.11it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.36it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.19it/s]

Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 382.35it/s]
/data/aiuser3/LLM_EvalPipeline_test/.venv/lib/python3.12/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  self.setter(val)
ğŸ”§ Frozen ëª¨ë¸ì„ GPUì— ë¡œë“œ
ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...
ğŸ” Forget ë°ì´í„°ì…‹: ['datasets/elude_etu/elon_musk/forget.jsonl']
ğŸ” Retain ë°ì´í„°ì…‹: ['datasets/elude_etu/elon_musk/retain_neighbors.jsonl']
ğŸ”§ Final layer_ids: [6, 7, 8]
ğŸ”§ Final lora_target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj']
Processing corpus spec: 'datasets/elude_etu/elon_musk/forget.jsonl'
Loading local file: datasets/elude_etu/elon_musk/forget.jsonl
Loaded 9637 items from local file
Processing corpus spec: 'datasets/elude_etu/elon_musk/retain_neighbors.jsonl'
Loading local file: datasets/elude_etu/elon_musk/retain_neighbors.jsonl
Loaded 1283198 items from local file
Data loading complete: 1 forget splits (4819 batches), 1 retain splits (641599 batches)
====ETU Config====
gpu_id=0
multi_gpu=False
strategy=ddp
batch_size_per_gpu=8
batch_size=2
max_num_batches=5
frozen_on_cpu=False
epsilon=0.1
lambda_max=50.0
lambda_update_freq=1
forget_corpora=datasets/elude_etu/elon_musk/forget.jsonl
retain_corpora=datasets/elude_etu/elon_musk/retain_neighbors.jsonl
model_name_or_path=HuggingFaceH4/zephyr-7b-beta
deterministic=False
verbose=True
gradient_accumulation_steps=4
mixed_precision=bf16
trust_remote_code=False
lr=1e-05
num_epochs=1
min_len=10
max_len=512
layer_id=None
layer_ids=[6, 7, 8]
param_ids=None
name_keywords=q_proj,k_proj,v_proj,o_proj
module_str={model_name}.model.layers[{layer_id}]
use_lora=True
lora_r=16
lora_alpha=512
lora_dropout=0.1
lora_target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj']
use_pmi_vs=True
vocab_top_k=100
vs_freq_rate=0.0
vs_abs_cap=50
pmi_top_k=1000
pmi_min_count=10
pmi_smoothing=0.1
pmi_max_batches=500
vs_preview_k=10
vs_debug=False
vs_debug_topk=200
span_masking=False
span_ngram_max=3
allow_negative_lambda=False
lambda_eta=1.0
pinsker_cap=0.1
use_upper_for_lambda=True
wilson_max_n=1000
log_every=10
output_dir=
seed=None
retain_weight=0.0
retain_broadcast=False
preference_weight=0.0
pref_every=10
pref_format=dpo
pref_beta=0.1
pref_margin=0.1
pref_max_len=512
=====
Applying LoRA for efficient parameter updates...
Applying LoRA to layers: [6, 7, 8]
trainable params: 1,277,952 || all params: 7,243,010,048 || trainable%: 0.0176
Building forbidden token set V_S...
[V_S] ìˆ˜ë™ V_S ê²½ë¡œ ì¶”ë¡ : datasets/elude_etu/elon_musk/V_S.ids.json
[V_S] ìˆ˜ë™ V_S íŒŒì¼ ë¡œë“œ: datasets/elude_etu/elon_musk/V_S.ids.json
[V_S] ìˆ˜ë™ V_S ë¡œë“œ ì„±ê³µ: 45ê°œ í† í°
[V_S] ìœ íš¨í•œ ìˆ˜ë™ V_S: 45ê°œ í† í°
[V_S] ìŠ¤í†±ë¦¬ìŠ¤íŠ¸ë¡œ 8ê°œ í† í° ì œê±°ë¨
V_S (PMI-refined) size: 37 tokens
[warn] PMI V_S too small â†’ fallback to freq-based augmentation
[V_S] ìˆ˜ë™ V_S íŒŒì¼ ë¡œë“œ: datasets/elude_etu/elon_musk/V_S.ids.json
[V_S] ìˆ˜ë™ V_S ë¡œë“œ ì„±ê³µ: 45ê°œ í† í°
[V_S] ìœ íš¨í•œ ìˆ˜ë™ V_S: 45ê°œ í† í°
[V_S] ìŠ¤í†±ë¦¬ìŠ¤íŠ¸ë¡œ 8ê°œ í† í° ì œê±°ë¨
V_S after fallback: 37 tokens
V_S fallback preview: ['on', 'ize', 'ink', 'â–car', 'â–Re', 'rol', 'ret', 'â–El', 'ural', 'la']
Top PMI tokens preview: ['on', 'ize', 'ink', 'â–car', 'â–Re', 'rol', 'ret', 'â–El', 'ural', 'la']
V_S size: 37 tokens (0.1% of vocab)
Estimating base probability mass p_S over V_S...
Estimated p_S (Ï€_base over V_S): 0.0510
[info] |V_S|/V = 0.1%, Ï€_base(S)=0.0510, Îµ=0.1000
V_S preview: ['on', 'ize', 'ink', 'â–car', 'â–Re', 'rol', 'ret', 'â–El', 'ural', 'la']
Initial Î»: 0.0000 â†’ expected qÎ»(S)â‰ˆ0.0510
======= Epoch 0 =======

  0%|          | 0/5 [00:00<?, ?it/s]
  0%|          | 0/5 [00:00<?, ?it/s, loss=-2.37e-08, Ï€Î¸(S)=0.141, Î»=1.00]
 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.49it/s, loss=-2.37e-08, Ï€Î¸(S)=0.141, Î»=1.00]
 20%|â–ˆâ–ˆ        | 1/5 [00:01<00:02,  1.49it/s, loss=0.00207, Ï€Î¸(S)=0.073, Î»=2.00]  
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:01,  1.57it/s, loss=0.00207, Ï€Î¸(S)=0.073, Î»=2.00]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:01,  1.57it/s, loss=0.0492, Ï€Î¸(S)=0.109, Î»=3.25] 
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:01,  1.59it/s, loss=0.0492, Ï€Î¸(S)=0.109, Î»=3.25]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:02<00:01,  1.59it/s, loss=0.0148, Ï€Î¸(S)=0.016, Î»=3.25]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:02<00:00,  1.55it/s, loss=0.0148, Ï€Î¸(S)=0.016, Î»=3.25]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:03<00:00,  1.55it/s, loss=0.134, Ï€Î¸(S)=0.141, Î»=3.25] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.59it/s, loss=0.134, Ï€Î¸(S)=0.141, Î»=3.25]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.57it/s, loss=0.134, Ï€Î¸(S)=0.141, Î»=3.25]
[HIGH] Ï€Î¸(S)=0.1410 [95% normal 0.0000,0.3233 | Wilsonâ†‘ 0.3973] | E[qÎ»(S)]=0.0510 | Îµ=0.1000 | KL=-2.37e-08 | Î»=0.000
[Î»-update] EMA Ï€Î¸(S)=0.1128 (controller=0.3650) â†’ Î»=0.000â†’1.000 | E[qÎ»(S)]=0.0194 | KL_EMA=-0.0000
[OK] Ï€Î¸(S)=0.0729 [95% normal 0.0000,0.2200 | Wilsonâ†‘ 0.2362] | E[qÎ»(S)]=0.0194 | Îµ=0.1000 | KL=0.002071 | Î»=1.000
[Î»-update] EMA Ï€Î¸(S)=0.0958 (controller=0.2656) â†’ Î»=1.000â†’2.000 | E[qÎ»(S)]=0.0072 | KL_EMA=0.0209
[NEAR] Ï€Î¸(S)=0.1091 [95% normal 0.0000,0.2934 | Wilsonâ†‘ 0.2483] | E[qÎ»(S)]=0.0072 | Îµ=0.1000 | KL=0.04918 | Î»=2.000
[Î»-update] EMA Ï€Î¸(S)=0.0962 (controller=0.2322) â†’ Î»=2.000â†’3.250 | E[qÎ»(S)]=0.0021 | KL_EMA=0.0904
[OK] Ï€Î¸(S)=0.0155 [95% normal 0.0000,0.0828 | Wilsonâ†‘ 0.0979] | E[qÎ»(S)]=0.0021 | Îµ=0.1000 | KL=0.0148 | Î»=3.250
[Î»-update] EMA Ï€Î¸(S)=0.0830 (controller=0.1922) â†’ Î»=3.250â†’3.250 | E[qÎ»(S)]=0.0021 | KL_EMA=0.2533
[HIGH] Ï€Î¸(S)=0.1411 [95% normal 0.0000,0.3304 | Wilsonâ†‘ 0.2477] | E[qÎ»(S)]=0.0021 | Îµ=0.1000 | KL=0.1336 | Î»=3.250
[Î»-update] EMA Ï€Î¸(S)=0.0881 (controller=0.1837) â†’ Î»=3.250â†’3.250 | E[qÎ»(S)]=0.0021 | KL_EMA=0.3205
=== ETU Suppression Report ===
  - Perplexity on retain: 1540.31
=== Results ===
  - Ï€_base(S): 0.0592
  - Ï€_Î¸(S): 0.0586
  - Suppression ratio: 0.99 (updated/base)
  - Target Îµ: 0.1000
  - Target achieved: âœ“
  - 95% upper Ï€_base(S): 0.0790
  - 95% upper Ï€_Î¸(S): 0.0783
  - Target achieved (95% upper): âœ“
Saved suppression report to models/zephyr-7b-beta_etu_epsilon-0.1_lambda-3.2500_2025-10-21-22-02-14/suppression_report.json
Merging LoRA weights into base model...
Saved V_S to models/zephyr-7b-beta_etu_epsilon-0.1_lambda-3.2500_2025-10-21-22-02-14/V_S.ids.json
Saved ETU model to models/zephyr-7b-beta_etu_epsilon-0.1_lambda-3.2500_2025-10-21-22-02-14
Saved args to models/zephyr-7b-beta_etu_epsilon-0.1_lambda-3.2500_2025-10-21-22-02-14/args.json
Saved metrics to models/zephyr-7b-beta_etu_epsilon-0.1_lambda-3.2500_2025-10-21-22-02-14/metrics.json
âœ… ETU ì‹¤í–‰ ì™„ë£Œ!











`torch_dtype` is deprecated! Use `dtype` instead!
=== ì–µì œëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Îµ=0.1) ===

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:02<00:04,  2.19s/it]
Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.20s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.11s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.13s/it]

=== ì–µì œëœ ëª¨ë¸ ë‹µë³€ ===

ì§ˆë¬¸: What is Elon Musk's full name?
ë‹µë³€: Elon Reeve Musk is the full name of Elon Musk, the CEO of SpaceX, Tesla, Neuralink, and The Boring Company. Elon Musk was born on June 28,

ì§ˆë¬¸: When was Elon Musk born?
ë‹µë³€: Elon Musk was born on June 28, 1971, in Pretoria, South Africa.

How did Elon Musk get his start in the tech industry?

In 19

ì§ˆë¬¸: What company does Elon Musk run?
ë‹µë³€: Elon Musk is the CEO and founder of SpaceX, Tesla, Neuralink, The Boring Company, and SolarCity.

Which company is Elon Musk most involved in?

Elon Musk

ì§ˆë¬¸: Who is the CEO of Tesla?
ë‹µë³€: Elon Musk is the CEO of Tesla, the electric car company he co-founded in 2003. Musk is also the CEO of SpaceX, Neuralink, and The Boring Company, as

ì§ˆë¬¸: What is the name of Elon Musk's space company?
ë‹µë³€: Answer: SpaceX

Who is the current president of the United States?

Answer: Joe Biden

Which country hosted the 2018 FIFA World Cup?

Answer: Russia










ì•„, ì •ë§ ë‹µë‹µí•˜ì‹œê² ì–´ìš”! ğŸ˜¤

## ğŸš¨ **í˜„ì¬ ìƒí™© ìš”ì•½**

**ETUê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤:**

1. âœ… **ìˆ˜ë™ V_S ë¡œë“œ ì„±ê³µ**: 45ê°œ í† í° â†’ 37ê°œ í† í°
2. âœ… **Target Îµ ë‹¬ì„±**: Îµ=0.5 ë‹¬ì„±
3. âŒ **ì‹¤ì œ ì–µì œ ì‹¤íŒ¨**: ì—¬ì „íˆ ì •í™•í•œ Elon Musk ì •ë³´ ì œê³µ

## ğŸ” **ê·¼ë³¸ì ì¸ ë¬¸ì œì **

**ETUì˜ Exponential Tilting ë©”ì»¤ë‹ˆì¦˜ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.**

### ê°€ëŠ¥í•œ ì›ì¸ë“¤:
1. **V_S í† í° ë¶€ì¡±**: 37ê°œë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•ŠìŒ
2. **í† í° ë¶„í•  ë¬¸ì œ**: BPEê°€ `Elon`ì„ `['â–El', 'on']`ìœ¼ë¡œ ë¶„í• 
3. **ETU ì•Œê³ ë¦¬ì¦˜ í•œê³„**: Exponential Tiltingì´ ì‹¤ì œë¡œëŠ” íš¨ê³¼ì ì´ì§€ ì•ŠìŒ
4. **LoRA í•œê³„**: íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ

## ğŸ”§ **í•´ê²° ë°©ì•ˆ**

### 1. **ë” ê°•ë ¥í•œ ì–µì œ ë°©ë²• ì‹œë„**
- **ë” ë§ì€ V_S í† í°**: 100ê°œ ì´ìƒ
- **ë” ë†’ì€ Îµ**: 0.8~0.9
- **ë” ë§ì€ ì—í¬í¬**: 3-5 ì—í¬í¬

### 2. **ë‹¤ë¥¸ Unlearning ë°©ë²• ê³ ë ¤**
- **Fine-tuning ê¸°ë°˜ ì–µì œ**
- **RLHF ê¸°ë°˜ ì–µì œ**
- **Direct parameter editing**

### 3. **í˜„ì‹¤ì ì¸ ì ‘ê·¼**
- **ETUì˜ í•œê³„ ì¸ì •**
- **ë‹¤ë¥¸ unlearning í”„ë ˆì„ì›Œí¬ ì‚¬ìš©**

ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?

1. **ë” ê°•ë ¥í•œ ETU ì„¤ì •**ìœ¼ë¡œ ë§ˆì§€ë§‰ ì‹œë„
2. **ë‹¤ë¥¸ unlearning ë°©ë²•** íƒìƒ‰
3. **í˜„ì¬ ê²°ê³¼ë¡œ ë§Œì¡±**í•˜ê³  ë‹¤ë¥¸ ì‘ì—… ì§„í–‰
